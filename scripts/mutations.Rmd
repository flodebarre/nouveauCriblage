---
title: "Mutations"
author: "FD"
output: 
  html_document: 
      code_folding: hide
      toc: TRUE
      toc_float: TRUE
      self_contained: no
editor_options:
  chunk_output_type: console
---

Warning: The structure of the public datasets has changed, and I am updating this code. Currently, it does not compile if you try to knit it, you need to evaluate it bit by bit (I stopped after "Specific examples"). 

```{r, eval=FALSE}
rm(list = ls()) # I don't care what you think
for(i in dev.list()) dev.off()
setwd("scripts/")
```

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


Source of the data:  
<https://www.data.gouv.fr/fr/datasets/donnees-de-laboratoires-pour-le-depistage-indicateurs-sur-les-mutations/>

# Initializations

```{r}
# Whether to download the data
dlData <- FALSE
```


```{r}
# Set colors
library(RColorBrewer)
colMut <- brewer.pal(n = 8, name = "Dark2")

# Met palettes
# install.packages("MetBrewer")
library("MetBrewer")

colMut <- met.brewer("Redon", n = 7, type = "discrete")
# Colorblind Choices are: Austria, Cassatt1, Cassatt2, Cross, Degas, Derain, Egypt, Gauguin, Greek, Hiroshige, Hokusai1, Hokusai2, Hokusai3, Homer1, Homer2, Ingres, Isfahan1, Isfahan2, Juarez, Klimt, Lakota, Manet, Monet, Moreau, Morgenstern, Nattier, Navajo, NewKingdom, Nizami, OKeeffe1, OKeeffe2, Peru1, Peru2, Pillement, Pissaro, Redon, Renoir, Robert, Signac, Stevens, Tara, Thomas, Tiepolo, Troy, Tsimshian, VanGogh1, VanGogh2, VanGogh3, Veronese, and Wissing

colGrad <- met.brewer("Hiroshige", n = 7, type = "continuous")
# Note: 7 is hard-coded, this is the number of different intervals for variant assignation

col484K <- colMut[1]
col484Q <- colMut[2]
col452R <- colMut[3]
colD <- colMut[4]
colAC <- colMut[5]

colTotCrib <- gray(0)#colMut[8]
colTot <- colMut[7]

col452R.complement <- "#b37570"
colDL <- "#FFD390" # Données délissées


colON <- met.brewer("Tiepolo", n = 5, type = "discrete")
colOld <- colON[2]
colNew <- colON[3]
colCombined <- colON[5]

```

```{r}
unique.noNA <- function(x){
  unique(x[!is.na(x)])
}
```

```{r results='hide'}
# Sliding window functio
source("usefulFunctions.R")
```

# Load data 

## Criblage data

```{r}
# OLD URLS
URL_Deps_old <- "https://www.data.gouv.fr/fr/datasets/r/4d3e5a8b-9649-4c41-86ec-5420eb6b530c"
URL_Regions_old <- "https://www.data.gouv.fr/fr/datasets/r/5ff0cad6-f150-47ea-a4e0-57e354c1b2a4"
URL_France_old <- "https://www.data.gouv.fr/fr/datasets/r/848debc4-0e42-4e3b-a176-afc285ed5401"

# NEW URLS
URL_Regions <- "https://www.data.gouv.fr/fr/datasets/r/9ed7f76c-09bc-43fb-997a-a1733faa6e8b"
URL_France <- "https://www.data.gouv.fr/fr/datasets/r/7eade8d7-f79a-4c7f-8579-51f3f7104cfb"
URL_Deps <- "https://www.data.gouv.fr/fr/datasets/r/ba8219dc-948c-418a-9116-f792c79c54b8"
```

```{r}
# Needed to be done only once

# download.file(URL_France_old, 
#                 destfile="../data/muts_France_old.csv",
#                 method="curl",
#                 extra='-L')
# download.file(URL_Regions_old, 
#                 destfile="../data/muts_Regions_old.csv",
#                 method="curl",
#                 extra='-L')
# 
# download.file(URL_Deps_old, 
#                 destfile="../data/muts_Deps_old.csv",
#                 method="curl",
#                 extra='-L')

dat.France.old <- read.csv("../data/muts_France_old.csv", sep = ";", stringsAsFactors = FALSE)
dat.Regions.old <- read.csv("../data/muts_Regions_old.csv", sep = ";", stringsAsFactors = FALSE)
dat.Deps.old <- read.csv("../data/muts_Deps_old.csv", sep = ";", stringsAsFactors = FALSE)

```

```{r}
# Download files from repo
# Need to use extra option to follow the redirection

if(dlData){
  download.file(URL_France, 
                destfile="../data/muts_France.csv",
                method="curl",
                extra='-L')
  download.file(URL_Regions, 
                destfile="../data/muts_Regions.csv",
                method="curl",
                extra='-L')
  if(!is.na(URL_Deps)){
    download.file(URL_Deps, 
                destfile="../data/muts_Deps.csv",
                method="curl",
                extra='-L')
  }
}


system("git add ../data/muts_*.csv")
system("git commit -m 'update data'")


dat.France.new <- read.csv("../data/muts_France.csv", sep = ";", stringsAsFactors = FALSE)
dat.Regions.new <- read.csv("../data/muts_Regions.csv", sep = ";", stringsAsFactors = FALSE)

if(!is.na(URL_Deps)){
  dat.Deps.new <- read.csv("../data/muts_Deps.csv", sep = ";", stringsAsFactors = FALSE)
}


```


## Test data

Source: <https://www.data.gouv.fr/fr/datasets/donnees-relatives-aux-resultats-des-tests-virologiques-covid-19/#>

```{r}
URLtest_France <- "https://www.data.gouv.fr/fr/datasets/r/dd0de5d9-b5a5-4503-930a-7b08dc0adc7c"
URLtest_Reg <- "https://www.data.gouv.fr/fr/datasets/r/001aca18-df6a-45c8-89e6-f82d689e6c01"
URLtest_Dep <- "https://www.data.gouv.fr/fr/datasets/r/406c6a23-e283-4300-9484-54e78c8ae675"

if(dlData){
  download.file(URLtest_France, "../data/tests_France.csv")
  download.file(URLtest_Reg, "../data/tests_Reg.csv")
  download.file(URLtest_Dep, "../data/tests_Deps.csv")
  
  system("git add ../data/tests*csv")
  system("git commit -m 'update test data'")
}

tests.France <- read.csv("../data/tests_France.csv", sep = ";", stringsAsFactors = FALSE)
tests.Reg <- read.csv("../data/tests_Reg.csv", sep = ";", stringsAsFactors = FALSE)
tests.Deps <- read.csv("../data/tests_Deps.csv", sep = ";", stringsAsFactors = FALSE)
```


```{r}
# Criblage is without age classes: remove them now to avoid errors
tests.France <- tests.France[which(tests.France$cl_age90 == 0), ]
tests.Reg <- tests.Reg[which(tests.Reg$cl_age90 == 0), ]
tests.Deps <- tests.Deps[which(tests.Deps$cl_age90 == 0), ]

# Compute sliding averages
tests.France$P7j <- sliding.window(tests.France$P)
tests.France$T7j <- sliding.window(tests.France$T)

# Note: Sliding averages for Reg and Deps computed separately, because
# need to do it for each location independently
```


## Combine the old and new datasets

Useful functions

```{r}
pchOld <- 16
pchNew <- 15
pchCombined <- 5
lwdCombined <- 1.5

# Plot colums to check that things are done alright
compare.xy <- function(dat, col, addCombined = TRUE){
   # dat: dataset
   # col: column
  par(las = 1, xpd = TRUE)
  plot(dat$dateMid, dat[, paste0(col, ".x")], xlab = "", ylab = "", main = col, col = colNew, pch = pchNew)
  points(dat$dateMid, dat[, paste0(col, ".y")], col = colOld, pch = pchOld, cex = 1)
  
  if(addCombined){
    points(dat$dateMid, dat[, col], pch = pchCombined, col = colCombined, lwd = lwdCombined)
    legend("topleft", col = c(colNew, colOld, colCombined), pch = c(pchNew, pchOld, pchCombined), legend = c("new", "old", "combined"), bty = "n", lwd = c(1, 1, lwd = lwdCombined), lty = 0)
  }else{
    legend("topleft", col = c(colNew, colOld), pch = c(pchNew, pchOld), legend = c("new", "old"), bty = "n")
  }
  par(xpd = FALSE)
}

# Sum columns, in spite of NAs
computeSum <- function(dat, col){
  tmpx <- dat[, paste0(col, ".x")]
  tmpy <- dat[, paste0(col, ".y")]
  
  # Set NAs to 0
  tmpx[is.na(tmpx)] <- 0
  tmpy[is.na(tmpy)] <- 0
  
  # Return sum
  tmpx + tmpy
}
```

France

```{r mergeFrance}
tmp.France <- merge(dat.France.new, dat.France.old, all = TRUE, by = c("fra", "semaine"))
dim(dat.France.new)
dim(dat.France.old)
dim(tmp.France)
head(tmp.France)

# Format date
tmp.France$date1 <- as.Date(substring(tmp.France$semaine, 1, 10))
tmp.France$date2 <- as.Date(substring(tmp.France$semaine, 12, 21))

# Mid-interval date
tmp.France$dateMid <- tmp.France$date2 - 3

  # Rewrite time as days since beginning of the data
  tmp.France$time <- tmp.France$dateMid - min(tmp.France$dateMid)
  
# nb_crib
tmp.France$nb_crib <- computeSum(tmp.France, "nb_crib")
compare.xy(tmp.France, "nb_crib")

# nb_pos
tmp.France$nb_pos <- tmp.France$nb_pos.x # New ones for times >= 2021-01-06
tmp.France[is.na(tmp.France$nb_pos), "nb_pos"] <- tmp.France[is.na(tmp.France$nb_pos), "nb_pos.y"] # Old ones
compare.xy(tmp.France, "nb_pos")

# A0
tmp.France$nb_A0 <- computeSum(tmp.France, "nb_A0")
compare.xy(tmp.France, "nb_A0")

# A1
tmp.France$nb_A1 <- computeSum(tmp.France, "nb_A1")
compare.xy(tmp.France, "nb_A1")

# C0
tmp.France$nb_C0 <- computeSum(tmp.France, "nb_C0")
compare.xy(tmp.France, "nb_C0")

# C1
tmp.France$nb_C1 <- computeSum(tmp.France, "nb_C1")
compare.xy(tmp.France, "nb_C1")
```

Regions

```{r mergeRegions}
tmp.Regions <- merge(dat.Regions.new, dat.Regions.old, all = TRUE, by = c("reg", "semaine"))
dim(dat.Regions.new)
dim(dat.Regions.old)
dim(tmp.Regions)
head(tmp.Regions)
head(dat.Regions.new)

# Format date
tmp.Regions$date1 <- as.Date(substring(tmp.Regions$semaine, 1, 10))
tmp.Regions$date2 <- as.Date(substring(tmp.Regions$semaine, 12, 21))

# Mid-interval date
tmp.Regions$dateMid <- tmp.Regions$date2 - 3

  # Rewrite time as days since beginning of the data
  tmp.Regions$time <- tmp.Regions$dateMid - min(tmp.Regions$dateMid)


# nb_crib
tmp.Regions$nb_crib <- computeSum(tmp.Regions, "nb_crib")
compare.xy(tmp.Regions, "nb_crib")

# nb_pos
tmp.Regions$nb_pos <- tmp.Regions$nb_pos.x # New ones for times >= 2021-01-06
tmp.Regions[is.na(tmp.Regions$nb_pos), "nb_pos"] <- tmp.Regions[is.na(tmp.Regions$nb_pos), "nb_pos.y"] # Old ones
compare.xy(tmp.Regions, "nb_pos")

# A0
tmp.Regions$nb_A0 <- computeSum(tmp.Regions, "nb_A0")
compare.xy(tmp.Regions, "nb_A0")

# A1
tmp.Regions$nb_A1 <- computeSum(tmp.Regions, "nb_A1")
compare.xy(tmp.Regions, "nb_A1")

# C0
tmp.Regions$nb_C0 <- computeSum(tmp.Regions, "nb_C0")
compare.xy(tmp.Regions, "nb_C0")

# C1
tmp.Regions$nb_C1 <- computeSum(tmp.Regions, "nb_C1")
compare.xy(tmp.Regions, "nb_C1")
```

Departements

```{r mergeDeps}
if(!is.na(URL_Deps)){
  tmp.Deps <- merge(dat.Deps.new, dat.Deps.old, all = TRUE, by = c("dep", "semaine"))
  dim(dat.Deps.new)
  dim(dat.Deps.old)
  dim(tmp.Deps)
  head(tmp.Deps)
  head(dat.Deps.new)
  
  # Format date
  tmp.Deps$date1 <- as.Date(substring(tmp.Deps$semaine, 1, 10))
  tmp.Deps$date2 <- as.Date(substring(tmp.Deps$semaine, 12, 21))
  
  # Mid-interval date
  tmp.Deps$dateMid <- tmp.Deps$date2 - 3
  
  # Rewrite time as days since beginning of the data
  tmp.Deps$time <- tmp.Deps$dateMid - min(tmp.Deps$dateMid)
  
  
  # nb_crib
  tmp.Deps$nb_crib <- computeSum(tmp.Deps, "nb_crib")
  compare.xy(tmp.Deps, "nb_crib")
  
  # nb_pos
  tmp.Deps$nb_pos <- tmp.Deps$nb_pos.x # New ones for times >= 2021-01-06
  tmp.Deps[is.na(tmp.Deps$nb_pos), "nb_pos"] <- tmp.Deps[is.na(tmp.Deps$nb_pos), "nb_pos.y"] # Old ones
  compare.xy(tmp.Deps, "nb_pos")
  
  # A0
  tmp.Deps$nb_A0 <- computeSum(tmp.Deps, "nb_A0")
  compare.xy(tmp.Deps, "nb_A0")
  
  # A1
  tmp.Deps$nb_A1 <- computeSum(tmp.Deps, "nb_A1")
  compare.xy(tmp.Deps, "nb_A1")
  
  # C0
  tmp.Deps$nb_C0 <- computeSum(tmp.Deps, "nb_C0")
  compare.xy(tmp.Deps, "nb_C0")
  
  # C1
  tmp.Deps$nb_C1 <- computeSum(tmp.Deps, "nb_C1")
  compare.xy(tmp.Deps, "nb_C1")

}else{
  tmp.Deps <- dat.Deps.old
}



```


Rename data

```{r}
dat.France <- tmp.France
dat.Regions <- tmp.Regions
dat.Deps <- tmp.Deps
```



## Add dates

```{r, eval = FALSE}
# Already done with the new format!


# Format date
dat.France$date1 <- as.Date(substring(dat.France$semaine, 1, 10))
dat.France$date2 <- as.Date(substring(dat.France$semaine, 12, 21))

# Mid-interval date
dat.France$dateMid <- dat.France$date2 - 3

# Rewrite time as days since beginning of the data
dat.France$time <- dat.France$dateMid - min(dat.France$date2)


# Format date
dat.France.old$date1 <- as.Date(substring(dat.France.old$semaine, 1, 10))
dat.France.old$date2 <- as.Date(substring(dat.France.old$semaine, 12, 21))

# Mid-interval date
dat.France.old$dateMid <- dat.France.old$date2 - 3


# Format date
dat.Regions$date1 <- as.Date(substring(dat.Regions$semaine, 1, 10))
dat.Regions$date2 <- as.Date(substring(dat.Regions$semaine, 12, 21))
# Rewrite time as days since beginning of the data
dat.Regions$time <- dat.Regions$date2 - min(dat.Regions$date2)

# Mid-interval date
dat.Regions$dateMid <- dat.Regions$date2 - 3


# Format date
dat.Regions.old$date1 <- as.Date(substring(dat.Regions.old$semaine, 1, 10))
dat.Regions.old$date2 <- as.Date(substring(dat.Regions.old$semaine, 12, 21))
# Mid-interval date
dat.Regions.old$dateMid <- dat.Regions.old$date2 - 3


# Format date
dat.Deps$date1 <- as.Date(substring(dat.Deps$semaine, 1, 10))
dat.Deps$date2 <- as.Date(substring(dat.Deps$semaine, 12, 21))
# Rewrite time as days since beginning of the data
dat.Deps$time <- dat.Deps$date2 - min(dat.Deps$date2)

# Mid-interval date
dat.Deps$dateMid <- dat.Deps$date2 - 3 


# Format date
dat.Deps.old$date1 <- as.Date(substring(dat.Deps.old$semaine, 1, 10))
dat.Deps.old$date2 <- as.Date(substring(dat.Deps.old$semaine, 12, 21))
# Mid-interval date
dat.Deps.old$dateMid <- dat.Deps.old$date2 - 3 

```


## Combine criblage and tests

```{r}
# Turn dates into dates for merging
tests.France$dateMid <- as.Date(tests.France$jour)
tests.Reg$dateMid <- as.Date(tests.Reg$jour)
tests.Deps$dateMid <- as.Date(tests.Deps$jour)

unique(tests.Reg$reg)
unique(tests.Deps$dep)
unique(dat.Deps$dep)
head(tests.France)
head(dat.France)

dat.France <- merge(dat.France, tests.France, all = TRUE, by = "dateMid")

dat.Regions <- merge(dat.Regions, tests.Reg, all = TRUE, by = c("dateMid", "reg"))

if(!is.na(URL_Deps)){
  dat.Deps <- merge(dat.Deps, tests.Deps, all = TRUE, by = c("dateMid", "dep"))
}

```

## Geographic data

### Regions 

```{r}
# Codes regions
URL <- "https://www.data.gouv.fr/en/datasets/r/34fc7b52-ef11-4ab0-bc16-e1aae5c942e7"
dataFile <- "../data/coderegions.csv"

if(!file.exists(dataFile)){
  download.file(URL, dataFile)
}

codesRegions <- read.csv(dataFile, sep = ",", stringsAsFactors = FALSE)

# Turn into dictionary
regs <- codesRegions$nom_region
names(regs) <- as.character(codesRegions$code_region)

# Add region name
dat.Regions$reg_name <- regs[as.character(dat.Regions$reg)]

unique(dat.Regions$reg_name)
unique(dat.Regions[which(is.na(dat.Regions$reg_name)), "reg"])

```


### Departments

```{r}
# Add name
deps <- read.csv("../data/departement2020.csv", stringsAsFactors = FALSE)
# Turn into dictionnary
dps <- deps$libelle
names(dps) <- as.character(deps$dep)

if(!is.na(URL_Deps)){
  dat.Deps$departement <- dps[as.character(dat.Deps$dep)]

  unique(dat.Deps$departement)
  
  unique(dat.Deps[which(is.na(dat.Deps$departement)), "dep"])
  
  # 977 Saint-Barthélemy, 978 Saint-Martin
}

```



# (tmp Extractions)

```{r, eval = FALSE}
tmp <- dat.Regions[which(dat.Regions$reg_name == "Île-de-France"), ]

# dim(tmp)
write.csv(tmp, file = "../data/extractionIDF.csv", col.names = NULL)
```

# Quality control

```{r}
byy <- list(dateMid = dat.Regions$dateMid)
aggReg <- aggregate(dat.Regions[, c("nb_D0", "nb_D1")], by = byy, FUN = sum, na.rm = TRUE)
aggDep <- aggregate(dat.Deps[, c("nb_D0", "nb_D1")], by = list(dateMid = dat.Deps$dateMid), FUN = sum, na.rm = TRUE)

par(xpd = FALSE)
plot(dat.France$dateMid, dat.France$nb_D0 + dat.France$nb_D1, xlim = c(as.Date("2021-11-15"), Sys.Date()))
points(aggReg$dateMid, aggReg$nb_D0 + aggReg$nb_D1, col = 2)
points(aggDep$dateMid, aggDep$nb_D0 + aggDep$nb_D1, col = 3)

points(dat.France$dateMid, dat.France$nb_D1, xlim = c(as.Date("2021-11-15"), Sys.Date()), pch = 0)
points(aggReg$dateMid, aggReg$nb_D1, col = 2, pch = 0)
points(aggDep$dateMid, aggDep$nb_D1, col = 3, pch = 0)

```

# Plots 

## Numbers of tests

```{r}
plotNbCrib <- function(dat, quot = TRUE, addLegend = TRUE, tp = "l", lwd = 1.5){
  # dat: dataset to be plotted
  # quot: boolean to decide whether to plot the daily values (averaged over 7 days) [TRUE], or the sum over the last 7 days [FALSE]
  # addLegend: whether to add plot legend
  # tp: line type
  if(quot){denom <- 7}else{denom <- 1}
  par(las = 1)
  par(mar = c(2, 4, 3, 4))
  plot(as.Date(dat$dateMid), dat$nb_pos / denom, ylim = c(0, 1.05*max(dat$nb_pos / denom, na.rm = TRUE)), yaxs = "i", 
       type = tp, pch = 16, col = colTot, 
       lwd = lwd, 
       frame.plot = FALSE, 
       xlab = "", ylab = "")
  
  lines(as.Date(dat$dateMid), dat$nb_crib / denom, type = tp, pch = 16, col = colTotCrib)
  
  if(addLegend){
    legend(x = "topright", legend = c("Nb tests positifs", "Nb tests criblés", "Nb tests interprétables E484K", "Nb tests interprétables E484Q", "Nb tests interprétables L452R", "Nb tests interprétables colonne D", "Nb tests interprétables AC"), 
         col = c(colTot, colTotCrib, col484K, col484Q, col452R, colD, colAC), 
         #pch = 16, 
         lty = 1, box.col = gray(0, 0), bty = "n", 
         lwd = lwd)
  }
  
  lines(as.Date(dat$dateMid), (dat$nb_A0 + dat$nb_A1) / denom, type = tp, pch = 16, col = col484K, lwd = lwd)
  lines(as.Date(dat$dateMid), (dat$nb_B0 + dat$nb_B1) / denom, type = tp, pch = 16, col = col484Q, lwd = lwd)
  lines(as.Date(dat$dateMid), (dat$nb_C0 + dat$nb_C1) / denom, type = tp, pch = 16, col = col452R, lwd = lwd)
  lines(as.Date(dat$dateMid), (dat$nb_D0 + dat$nb_D1) / denom, type = tp, pch = 16, col = colD, lwd = lwd)
  lines(as.Date(dat$dateMid), (dat$nb_A01C01) / denom, type = tp, pch = 16, col = colAC, lwd = lwd)
  
  axis(4)
}
```

```{r}
plotTauxCrib <- function(dat){
  par(las = 1)
  par(mar = c(2, 4, 3, 4))
  plot(dat$dateMid, 100*dat$nb_crib / dat$nb_pos, ylim = c(0, 100), lwd = 3, col = gray(0.3), frame.plot = FALSE, 
       xlab = "", ylab = "", yaxs = "i", type = "p", pch = 16)
  # Show final point
  i <- which(dat$dateMid == max(dat$dateMid, na.rm = TRUE))
  points(dat$dateMid[i], 100*(dat$nb_crib / dat$nb_pos)[i], col = "red", pch = 16)
  axis(4)
}
```


```{r NbCribFrance}
plotNbCrib(dat.France)
title(main = "France")
```


```{r NbCribRegions}
# Plot all regions in single plots
# for(reg in unique.noNA(dat.Regions$reg_name)){
#   dat <- dat.Regions[dat.Regions$reg_name == reg, ]
#   plotNbCrib(dat, addLegend = FALSE)
#   title(main = reg)
# }
```


```{r}
# Function to plot one region
plotReg <- function(reg){
  dat <- dat.Regions[dat.Regions$reg_name == reg, ]
  plotNbCrib(dat, addLegend = FALSE)
  title(main = reg)
}

# Function to plot one region
plotRegTx <- function(reg){
  dat <- dat.Regions[dat.Regions$reg_name == reg & dat.Regions$dateMid > "2021-11-01", ]
  plotTauxCrib(dat)
  title(main = reg)
}

#[1] "Auvergne-Rhône-Alpes"       "Hauts-de-France"            "Provence-Alpes-Côte d'Azur" "Grand Est"                 
# [5] "Occitanie"                  "Normandie"                  "Nouvelle-Aquitaine"         "Centre-Val de Loire"       
# [9] "Corse"                      "Bourgogne-Franche-Comté"    "Bretagne"                   "Pays de la Loire"          
#[13] "Île-de-France"              "Guadeloupe"                 "Martinique"                 "Guyane"                 
#[17] "La Réunion"                 "Mayotte" 
```

```{r figRegionsMapNBCriblage, fig.width=10, fig.height=10}

layout(matrix(1:15, ncol = 3, byrow = TRUE))

# 1 Plot legend
par(mar = c(0, 0, 0, 0))

    
plot(0, 0, xlab = "", ylab = "", type = "n", axes = FALSE, xlim = c(-0.2, 1), ylim = c(-1, 0.5))
legend(x = 0, y = 0, legend = c("Nb tests positifs", "Nb tests criblés", "Nb tests interprétables E484K", "Nb tests interprétables E484Q", "Nb tests interprétables L452R", "Nb tests interprétables colonne D", "Nb tests interprétables AC"), 
         col = c(colTot, colTotCrib, col484K, col484Q, col452R, colD, colAC), 
         #pch = 16, 
         lty = 1, box.col = gray(0, 0), bty = "n", cex = 1)

# 2 HDF
plotReg("Hauts-de-France")

# 3 Plot credits
par(mar = c(0, 0, 0, 0))
plot(0, 0, xlab = "", ylab = "", type = "n", axes = FALSE, xlim = c(-0.1, 1), ylim = c(-1, 1))
text(0, 0, "@flodebarre 

Data:
https://www.data.gouv.fr/fr/datasets/
donnees-de-laboratoires-pour-le-
depistage-indicateurs-sur-les-mutations/

Code: https://github.com/flodebarre/
nouveauCriblage/blob/main/scripts/mutations.Rmd
", adj = 0, cex = 0.8, family = "mono")

# 4 NOR
plotReg("Normandie")

# 5 IDF
plotReg("Île-de-France")

# 6 GE
plotReg("Grand Est")

# 7 BRE
plotReg("Bretagne")

# 8 CVL
plotReg("Centre-Val de Loire")

# 9 BFC
plotReg("Bourgogne-Franche-Comté")

# 10 PDL
plotReg("Pays de la Loire")

# 11 ARA
plotReg("Auvergne-Rhône-Alpes")

# 12 PACA
plotReg("Provence-Alpes-Côte d'Azur")

# 13 NAQ
plotReg("Nouvelle-Aquitaine")

# 14 OCC
plotReg("Occitanie")

# 15 COR
plotReg("Corse")
#[1] "Auvergne-Rhône-Alpes"       "Hauts-de-France"            "Provence-Alpes-Côte d'Azur" "Grand Est"                 
# [5] "Occitanie"                  "Normandie"                  "Nouvelle-Aquitaine"         "Centre-Val de Loire"       
# [9] "Corse"                      "Bourgogne-Franche-Comté"    "Bretagne"                   "Pays de la Loire"  

```

```{r figRegionsMapTauxCriblage, fig.width=10, fig.height=10}

layout(matrix(1:15, ncol = 3, byrow = TRUE))

# 1 Plot legend
par(mar = c(0, 0, 0, 0))
plot(0, 0, xlab = "", ylab = "", type = "n", axes = FALSE, xlim = c(-0.2, 1), ylim = c(-1, 0.5))
text(0, 0, "Pourcentage de tests criblés", adj = c(0, 0), cex = 1.3)
text(0, 0, "(les données publiques sont déjà lissées, 
ce qui 'arrondit' les changements brutaux)", adj = c(0, 2))
# 2 HDF
plotRegTx("Hauts-de-France")

# 3 Plot credits
par(mar = c(0, 0, 0, 0))
plot(0, 0, xlab = "", ylab = "", type = "n", axes = FALSE, xlim = c(-0.1, 1), ylim = c(-1, 1))
text(0, 0, "@flodebarre 

Data:
https://www.data.gouv.fr/fr/datasets/
donnees-de-laboratoires-pour-le-
depistage-indicateurs-sur-les-mutations/

Code: https://github.com/flodebarre/
nouveauCriblage/blob/main/scripts/mutations.Rmd
", adj = 0, cex = 0.8, family = "mono")

# 4 NOR
plotRegTx("Normandie")

# 5 IDF
plotRegTx("Île-de-France")

# 6 GE
plotRegTx("Grand Est")

# 7 BRE
plotRegTx("Bretagne")

# 8 CVL
plotRegTx("Centre-Val de Loire")

# 9 BFC
plotRegTx("Bourgogne-Franche-Comté")

# 10 PDL
plotRegTx("Pays de la Loire")

# 11 ARA
plotRegTx("Auvergne-Rhône-Alpes")

# 12 PACA
plotRegTx("Provence-Alpes-Côte d'Azur")

# 13 NAQ
plotRegTx("Nouvelle-Aquitaine")

# 14 OCC
plotRegTx("Occitanie")

# 15 COR
plotRegTx("Corse")
#[1] "Auvergne-Rhône-Alpes"       "Hauts-de-France"            "Provence-Alpes-Côte d'Azur" "Grand Est"                 
# [5] "Occitanie"                  "Normandie"                  "Nouvelle-Aquitaine"         "Centre-Val de Loire"       
# [9] "Corse"                      "Bourgogne-Franche-Comté"    "Bretagne"                   "Pays de la Loire"  

```


## Proportions / Nb tests

### Generic

```{r}
plotMut <- function(time, test0, test1, col, thetit, ymax = 1, quot = TRUE, add = FALSE, pch = 16, annotate = TRUE){
  # quot: boolean to decide whether to plot the daily values (averaged over 7 days) [TRUE], or the sum over the last 7 days [FALSE]
  
  if(quot){denom <- 7}else{denom <- 1}
  n <- (test1 + test0) / denom
  p <- test1 / (test1 + test0)
  
  # Computation of the confidence interval
  deltaItv <- 1.96 * sqrt(p * (1-p) / n)
  keepPts <- !is.na(deltaItv) 
  # Remove points for which the itv cannot be computed
  deltaItv <- deltaItv[keepPts]
  pp <- p[keepPts]
  xx <- base::as.Date(time)[keepPts]

  par(mar = c(5, 4, 4, 4))
  par(las = 1)
  par(xpd = TRUE)
  if(!add){
    plot(as.Date(time), p, ylim = c(0, ymax), frame.plot = FALSE, 
     xlab = "", ylab = "p", yaxs = "i", xaxs = "i", 
     type = "p", col = col, pch = pch)
    par(xpd = FALSE)
    if(annotate){
        mtext("  Parmi les n(t) tests interprétables recherchant la mutation
  Intervalle de confiance binomial sur ce nombre de tests n(t)", side = 3, cex = 0.6, adj = 0, line = -1)
    }
#  mtext("date", line = 2, side = 1)  
  axis(4)
  # Add graduation
  for(i in seq(0, 1, by = 0.1)){
    abline(h = i, col = gray(0.9), lwd = 1.1)
  }
  for(i in seq(0.05, 0.95, by = 0.1)){
    abline(h = i, col = gray(0.9), lwd = 0.8)
  }
  
  if(annotate){
    mtext("Données : https://www.data.gouv.fr/fr/datasets/donnees-de-laboratoires-pour-le-depistage-indicateurs-sur-les-mutations/
Code : https://github.com/flodebarre/nouveauCriblage/blob/main/scripts/mutations.Rmd", side = 1, line = 3.5, cex = 0.6, col = gray(0.5), adj = 0, family = "mono")
  }

  title(main = thetit)

  }else{ # Else of add
    par(xpd = TRUE)
    points(as.Date(time), p,  
     type = "p", col = col, pch = pch)
  }
  par(xpd = FALSE)
  arrows(x0 = xx, x1 = xx, 
         y0 = pp - deltaItv, y1 = pp + deltaItv, 
         col = col, lwd = 1, code = 0)
#  polygon(x = c(xx, rev(xx), xx[1]), y = c(pp + deltaItv, rev(pp - deltaItv), (pp + deltaItv)[1]), border = NA, col = adjustcolor(col, alpha.f = 0.3))
  print(p[length(p)])
}
```


```{r}
plotMut0 <- function(time, test0, test1, col, thetit, ymin = 10^-6, ymax = 1 - 10^-6, quot = TRUE, scale = "logit", addNotes = TRUE, addDeliss = FALSE, timedl, test0dl, test1dl, coldl = colDL, addLegend = FALSE, add = FALSE, pch = 16){
  # -- here showing n0/(n0+n1) --
  # time: vector of values of times of sample collection
  # test0: vector of numbers of tests with value 0
  # test1: vector of numbers of tests with value 1
  # col: color used for the plot
  # thetit: title of the plot
  # ymin: min y value
  # ymax: max y value
  # quot: (quotidien) boolean to decide whether to plot the daily values (averaged over 7 days) [TRUE], or the sum over the last 7 days [FALSE]
  # scale: "logit" or "linear"
  # addNotes: whether to show warning notes on the plot
  # addDeliss: whether to add data délissées (if available)
  # timedl: time values of the délissées data
  # test0dl: C0 values délissées
  # test1dl: C1 values délissées
  # coldl: color for the délissées data
  # addLegend: whether to add legend
  # add: if add to already existing plot
  
  if(quot){denom <- 7}else{denom <- 1}
  n <- (test1 + test0) / denom
  p <- test0 / (test1 + test0)
  
  # Computation of the confidence interval
  deltaItv <- 1.96 * sqrt(p * (1-p) / n)
  keepPts <- !is.na(deltaItv) 
  # Remove points for which the interval cannot be computed
  deltaItv <- deltaItv[keepPts]
  pp <- p[keepPts]
  
  dxx <- 0 # Number of days to be added (depends on whether data délissées are used)
  
  cexL <- 1 # Point size of lissées data
  if(addDeliss){cexL <- 1.2}
  
  if(addDeliss){
    dxx <- 3 # 3 more days if data délissées are added
    ndl <- (test1dl + test0dl)
    pdl <- test0dl / (test0dl + test1dl)
    deltaItvdl <- 1.96 * sqrt(pdl * (1-pdl) / ndl)
    keepPtsdl <- !is.na(deltaItvdl) 
    # Remove points for which the interval cannot be computed
    deltaItvdl <- deltaItvdl[keepPtsdl]
    ppdl <- pdl[keepPtsdl]
  }

  # Compute new values on the new scale
  changeScale <- function(p, confInt = FALSE){
    out <- NA # Initialize output, have NA if scale not properly written
    if(scale == "logit"){
      # Make sure that p is between 0 and 1 (can be different with conf int)
      p[p < ymin] <- max(0, 0.5*ymin)
      p[p > ymax] <- 2*ymax
      
      out <- log(p /(1-p)) # Logit scale
    }
    if(scale == "linear"){
      out <- p # Linear scale, no change
    }
    out
  }

  par(mar = c(5, 4, 4, 4))
  par(las = 1, mgp = c(2.5, 0.3, 0), tck = -0.01)
  
  xmin <- min(as.Date(time), na.rm = TRUE)
  xmax <- max(as.Date(time), na.rm = TRUE)
  if(addDeliss){
     xmax <- xmax + 3
  }
  

  if(!add){
    # Create new plot
    plot(as.Date(time), changeScale(p), 
       ylim = c(changeScale(ymin), changeScale(ymax)), 
       xlim = c(xmin, xmax),
       frame.plot = FALSE, 
       xlab = "", ylab = "", 
       col = col, pch = 16, 
       axes = FALSE, 
       yaxs = "i", type = "n")

      # Add graduations
      if(scale == "linear"){
        colGrad <- gray(0.85)
        for(i in seq(0, 1, by = 0.1)){
          abline(h = i, col = colGrad, lwd = 1.2)
        }
        for(i in seq(0.05, 0.95, by = 0.1)){
          #      abline(h = i, col = colGrad, lwd = 0.8)
        }
        abline(h = 0.5, col = colGrad, lwd = 3)
      }
      
    }  
  

  
  # if(addNotes){
  #   text(x = as.Date(time[1]), y = changeScale(ymax), labels = paste0("  Données jusqu'au ", format(as.Date(max(time)) + dxx, "%d/%m/%Y"), 
  # "
  # 
  # Proportion p0 = C0 / (C0 + C1) parmi les tests interprétables recherchant la mutation
  # Intervalle de confiance binomial sur ce nombre de tests interprétables  
  # 
  # Attention : 
  # - Les données publiques sont données partagées déjà lissées sur 7j, ce qui atténue le signal
  # - Le nombre de résultats de criblage rendus publics est actuellement faible"), cex = 0.65, adj = c(0, 1))
  # }

  
  # Label of the horizontal axis
  #mtext("date", line = 2, side = 1)  

  xx <- base::as.Date(time)[keepPts]

  # Add data points (lissés)    
  points(as.Date(time), changeScale(p), 
       type = "p", col = col, pch = pch, cex = cexL)
  
  # Add confidence interval as arrows
  arrows(x0 = xx, 
         x1 = xx, 
         y0 = changeScale(pp - deltaItv), 
         y1 = changeScale(pp + deltaItv), 
         code = 0, 
         lwd = 3, 
         col = adjustcolor(col, alpha.f = 0.5), 
         lend = 1)

  
  
  # If add "delissees" data
  if(addDeliss){
    points(as.Date(timedl), changeScale(pdl), type = "p", col = coldl, pch = 16)

    xxdl <- base::as.Date(timedl)[keepPtsdl]

    # Add confidence interval as arrows
    arrows(x0 = xxdl, 
         x1 = xxdl, 
         y0 = changeScale(ppdl - deltaItvdl), 
         y1 = changeScale(ppdl + deltaItvdl), 
         code = 0, 
         lwd = 3, 
         col = adjustcolor(coldl, alpha.f = 0.5), 
         lend = 1)
  }
  

  if(addNotes){
  # Add note about data and code provenance
  mtext("Données : https://www.data.gouv.fr/fr/datasets/donnees-de-laboratoires-pour-le-depistage-indicateurs-sur-les-mutations/
Code : https://github.com/flodebarre/nouveauCriblage/blob/main/scripts/mutations.Rmd", side = 1, line = 3.5, cex = 0.5, col = gray(0.5), adj = 0, family = "mono")
    
    par(xpd = TRUE)
    if(addLegend){
      legend("topleft", col = c(col, coldl), pch = 16, legend = c("Données publiques, publiées déjà lissées", "Données délissées"), bty = "n", horiz = TRUE, cex = 0.8, pt.cex = 0.9*c(cexL, 1), inset = c(0, -0.075))
    }
    par(xpd = FALSE)
  }

  
  if(!add){
    # Axes: 
    # horizontal
    xxl <- seq(as.Date(min(time)), as.Date(max(time)) + dxx, by = "day")
    axis(1, at = xxl, 
         labels = format(seq(as.Date(min(time)), as.Date(max(time)) + dxx, by = "day"), "%d/%m"), 
         las = 2, 
         cex.axis = 0.6, 
         lwd = 0)
    
    # Vertical axes
    if(scale == "linear"){
      axis(2, lwd = 0)
      axis(4, lwd = 0)
    }
    if(scale == "logit"){
      yvalues <- c(0.999, 0.99, 0.9, 0.75, 0.5, 0.25, 0.1, 0.05, 0.025, 0.01, 0.001)
      axis(2, at = changeScale(yvalues), labels = yvalues)
      axis(4, at = changeScale(yvalues), labels = yvalues)
    }
    
    if(scale == "linear"){
      mtext("Proportion criblage sans mutation L452R", side = 2, las = 0, line = 2.5)
    }
    if(scale == "logit"){
      mtext(expression(paste("p"[0], ", logit scale")), side = 2, las = 0, line = 2.5)
    }
    
    title(main = thetit)
    
  }
  print(p[length(p)])
}

layout(1)
ix <- which(dat.France$dateMid >= "2021-11-01")
#plotMut0(dat.France[ix, "dateMid"], dat.France[ix, "nb_C0"], dat.France[ix, "nb_C1"], col = col452R, thetit = "Proportion des tests criblés sans la mutation L452R, France", ymin = 10^-2, ymax = 0.6)


#plotRegC0("Île-de-France", addNotes = TRUE)

layout(1)
#plotRegC0("Île-de-France", addNotes = TRUE, ymax = 0.99, addLegend = TRUE)

#plotRegC0("Île-de-France", addNotes = TRUE, ymax = 1, ymin = 0, addLegend = TRUE, scale = "linear")


```

### France 

```{r}
plotMut(dat.France$dateMid, dat.France$nb_A0, dat.France$nb_A1, col = col484K, thetit = "Proportion of cases with \nE484K, France", ymax = 0.3)
plotMut(dat.France$dateMid, dat.France$nb_B0, dat.France$nb_B1, col = col484Q, thetit = "Proportion of cases with \nE484Q, France", ymax = 0.3)
plotMut(dat.France$dateMid, dat.France$nb_C0, dat.France$nb_C1, col = col452R, thetit = "L452R, France")
```



### Regions 

```{r regionsPlot, eval = FALSE}
for(reg in unique.noNA(dat.Regions$reg_name)){
  dat <- dat.Regions[dat.Regions$reg_name == reg, ]
  plotMut(time = dat$dateMid, test0 = dat$nb_C0, test1 = dat$nb_C1, col = col452R, thetit = paste0("L452R, ", reg), ymax = 1)
}



for(reg in unique.noNA(dat.Regions$reg_name)){
  dat <- dat.Regions[which(dat.Regions$reg_name == reg & dat.Regions$date2 >= "2021-11-01"), ]
  plotMut(time = dat$date2, test0 = dat$nb_A0, test1 = dat$nb_A1, col = col484K, thetit = paste0("E484K, ", reg), ymax = 0.2)
}

```

### Specific examples

-  PACA and B.1.640.2

```{r}
unique(dat.Regions$nom_reg)
tmp <- dat.Regions[which(dat.Regions$nom_reg == "Provence-Alpes-Côte d'Azur" & dat.Regions$dateMid >= "2021-11-15"), ]

plotMut(time = tmp$dateMid, test0 = tmp$nb_A0, test1 = tmp$nb_A1, col = col484K, thetit = "Provence-Alpes-Côte d'Azur")

plotMut(time = tmp$dateMid, test1 = tmp$nb_C0, test0 = tmp$nb_C1, col = col452R, thetit = "Provence-Alpes-Côte d'Azur", add = TRUE)

plotMut(time = tmp$dateMid, test1 = tmp$nb_A0C0, test0 = tmp$nb_A01C01 - tmp$nb_A0C0, col = colAC, thetit = "Provence-Alpes-Côte d'Azur", add = TRUE)

legend(x = as.Date("2021-11-16"), y = 0.8, 
       col = c(col452R, colAC, col484K), 
       legend = c("Proportion non-L452R", 
                  "Proportion non-L452R and non-E484K", 
                  "Proportion E484K"), 
       pch = 16, box.lwd = 0)
```

-  Comparing targets

```{r compareTargetsCriblage}
startDate <- "2021-11-25"
endDate <- Sys.Date() - 6
  

  
pchNew <- 2
pchOld <- 6

pchAC <- 18
pchD <- 15

compareOldNew <- FALSE

plotCompareTargets <- function(tmp, rg = "", compareOldNew = FALSE, addAnnotations = FALSE){
  # tmp: dataset to be plotted
  # compareOldNew: whether to compare old and new versions of the data
  
  plotMut(time = tmp$dateMid, test1 = tmp$nb_C0, test0 = tmp$nb_C1, col = col452R, thetit = rg, annotate = addAnnotations)
  
  if(compareOldNew){
    plotMut(time = tmp$dateMid, test1 = tmp$nb_C0.x, test0 = tmp$nb_C1.x, col = col452R, thetit = rg, add = TRUE, pch = pchNew, annotate = addAnnotations)
    plotMut(time = tmp$dateMid, test1 = tmp$nb_C0.y, test0 = tmp$nb_C1.y, col = col452R, thetit = rg, add = TRUE, pch = pchOld, annotate = addAnnotations)
  }
  
  plotMut(time = tmp$dateMid, test0 = tmp$nb_D0, test1 = tmp$nb_D1, col = colD, thetit = rg, add = TRUE, pch = pchD, annotate = addAnnotations)
  
  plotMut(time = tmp$dateMid, test1 = tmp$nb_A0C0, test0 = tmp$nb_A01C01 - tmp$nb_A0C0, col = colAC, thetit = rg, add = TRUE, pch = pchAC, annotate = addAnnotations)
  
  if(addAnnotations){
      legend(x = as.Date("2021-11-26"), 
         y = 0.9, 
         col = c(col452R, colAC, colD), 
         pch = c(16, pchAC, pchD), 
         legend = c("non-L452R", "non-E484K & non-L452R", "D1"), 
         box.lwd = -1)
  }
  
  xx <- seq(min(tmp$dateMid), max(tmp$dateMid), by = "day")
  axis(1, at = xx, labels = rep("", length(xx)), lwd = 0, lwd.ticks = 1, tck = -0.01)

}
```


```{r compareTargetsCriblageFrance}
layout(1)
tmp <- dat.France[which(dat.France$dateMid >= startDate & dat.France$dateMid <= endDate), ]
rg <- "France"
plotCompareTargets(tmp, rg, addAnnotations = TRUE)
```


```{r}
plotMut0(time = tmp$dateMid, test0 = tmp$nb_C0, test1 = tmp$nb_C1, col = col452R, thetit = rg, ymin = 0.01, ymax = 0.99)
  
  plotMut0(time = tmp$dateMid, test0 = tmp$nb_C0.y, test1 = tmp$nb_C1.y, col = col452R, thetit = rg, ymin = 0.01, ymax = 0.99)
  
  plotMut0(time = tmp$dateMid, test0 = tmp$nb_C0, test1 = tmp$nb_C1, col = col452R, thetit = rg, ymin = 0.01, ymax = 0.99)


```

#### Regions

```{r compareTargetsRegions, fig.width=9, fig.height=12}
plotCompareTargetsReg <- function(region){
  tmp <- dat.Regions[which(dat.Regions$nom_reg == region & dat.Regions$dateMid >= startDate & dat.Regions$dateMid <= endDate), ]
  rg <- region
  plotCompareTargets(tmp, rg, addAnnotations = FALSE)
}

layout(matrix(1:15, ncol = 3, byrow = TRUE))
par(las = 1)

# 1 Plot legend (no)
par(mar = c(0, 0, 0, 0))
plot(0, 0, xlab = "", ylab = "", type = "n", axes = FALSE, xlim = c(-0.2, 1), ylim = c(-1, 0.5))
legend(x = -0.15, y = 0, 
         col = c(col452R, colAC, colD), 
         pch = c(16, pchAC, pchD), 
         legend = c("non-L452R", "non-E484K & non-L452R", "D1"), 
         box.lwd = -1, cex = 1.2)

# 2 HDF
#layout(1)
marplot <- c(2, 2, 2, 2)
par(mar = marplot)
plotCompareTargetsReg("Hauts-de-France")


# 3 Plot credits
par(mar = c(0, 0, 0, 0))
plot(0, 0, xlab = "", ylab = "", type = "n", axes = FALSE, xlim = c(-0.1, 1), ylim = c(-1, 1))
text(0, 0, paste0("@flodebarre, ", max(dat.France$date2, na.rm = TRUE) + 3, "

Data:
https://www.data.gouv.fr/fr/datasets/
donnees-de-laboratoires-pour-le-
depistage-indicateurs-sur-les-mutations/
and 
https://www.data.gouv.fr/fr/datasets/
donnees-relatives-aux-resultats-des-
tests-virologiques-covid-19/

Code: https://github.com/flodebarre/
nouveauCriblage/blob/main/scripts/mutations.Rmd
"), adj = 0, cex = 0.6, family = "mono")

par(mar = marplot)

# 4 NOR
plotCompareTargetsReg("Normandie")

# 5 IDF
# 
#layout(1)
plotCompareTargetsReg("Ile-de-France")

# 6 GE
plotCompareTargetsReg("Grand Est")

# 7 BRE
plotCompareTargetsReg("Bretagne")

# 8 CVL
plotCompareTargetsReg("Centre-Val de Loire")

# 9 BFC
plotCompareTargetsReg("Bourgogne-Franche-Comté")

# 10 PDL
plotCompareTargetsReg("Pays de la Loire")

# 11 ARA
plotCompareTargetsReg("Auvergne-Rhône-Alpes")

# 12 PACA
plotCompareTargetsReg("Provence-Alpes-Côte d'Azur")

# 13 NAQ
plotCompareTargetsReg("Nouvelle-Aquitaine")

# 14 OCC
plotCompareTargetsReg("Occitanie")

# 15 COR
plotCompareTargetsReg("Corse")
```


#### Departements

-  Ile-de-France

```{r compareTargetsDepsIDF, fig.width=10, fig.height=10}
plotCompareTargetsDep <- function(dep){
  tmp <- dat.Deps[which(dat.Deps$departement == dep & dat.Deps$dateMid >= startDate & dat.Deps$dateMid <= endDate), ]
  rg <- dep
  plotCompareTargets(tmp, rg, addAnnotations = FALSE)
}


layout(matrix(1:9, ncol = 3, byrow = TRUE))

# 95
plotCompareTargetsDep("Val-d'Oise")

# 93
plotCompareTargetsDep("Seine-Saint-Denis")

# 77
plotCompareTargetsDep("Seine-et-Marne")

# 92
plotCompareTargetsDep("Hauts-de-Seine")

# 75
plotCompareTargetsDep("Paris")

# 94
plotCompareTargetsDep("Val-de-Marne")

# 78
plotCompareTargetsDep("Yvelines")

# 91
plotCompareTargetsDep("Essonne")


# Credits
par(mar = c(0, 0, 0, 0))
plot(0, 0, xlab = "", ylab = "", type = "n", axes = FALSE, xlim = c(-0.2, 1), ylim = c(-1, 0.5))
legend(x = -0.15, y = 0.25, 
         col = c(col452R, colAC, colD), 
         pch = c(16, pchAC, pchD), 
         legend = c("non-L452R", "non-E484K & non-L452R", "D1"), 
         box.lwd = -1, cex = 1.2)
text(x = -0.15, y = -0.15, adj = c(0, 1), paste0("@flodebarre, ", max(dat.France$date2, na.rm = TRUE) + 3, "

Data:
https://www.data.gouv.fr/fr/datasets/
donnees-de-laboratoires-pour-le-
depistage-indicateurs-sur-les-mutations/
and 
https://www.data.gouv.fr/fr/datasets/
donnees-relatives-aux-resultats-des-
tests-virologiques-covid-19/

Code: https://github.com/flodebarre/
nouveauCriblage/blob/main/scripts/mutations.Rmd
"), cex = 0.55, family = "mono")

```


We cannot do this anymore with the new data...

```{r, eval = FALSE}
# Source function to turn back into raw data 
source("delissage.R")
```


```{r figRegionsMapPropC0, fig.width=10, fig.height=15, eval = FALSE}

# Function to plot one region
# We set et all parameters here
plotRegC0 <- function(reg, xmin = "2021-11-01", addNotes = FALSE, ymax = 0.99, ymin = 0.5*10^-2, ...){
  dat <- dat.Regions[which(dat.Regions$reg_name == reg & dat.Regions$dateMid >= xmin), ]
  
  # Delissage
  tmp <- delissage(reg)
  tmp <- tmp[which(tmp$date2 >= xmin), ]
  
  # Export
  regNB <- unique(dat$reg)
  write.csv(tmp, file = paste0("../data/deliss_reg-", regNB, ".csv"))
  
  plotMut0(dat$dateMid, dat$nb_C0, dat$nb_C1, col = col452R, thetit = "", 
           ymin = ymin, ymax = ymax, 
           addDeliss = TRUE, 
           timedl = tmp$date2,
           test0dl = tmp$nb_C0_dl, 
           test1dl = tmp$nb_C1_dl, 
           addNotes = addNotes,...)
#ix <- which(dat.France$date2 > "2021-11-01")
#plotMut0(dat.France[ix, "date2"], dat.France[ix, "nb_C0"], dat.France[ix, "nb_C1"], col = col452R, thetit = "L452R, France", ymin = 10^-2, ymax = 0.6)
  title(main = reg)
}


#
#ix <- which(dat.France$date2 > "2021-11-01")
#plotMut0(dat.France[ix, "date2"], dat.France[ix, "nb_C0"], dat.France[ix, "nb_C1"], col = col452R, thetit = "L452R, France", ymin = 10^-2, ymax = 0.6)

layout(matrix(1:15, ncol = 3, byrow = TRUE))

# 1 Plot legend
par(mar = c(0, 0, 0, 0))
plot(0, 0, xlab = "", ylab = "", type = "n", axes = FALSE, xlim = c(-0.2, 1), ylim = c(-1, 0.5))
legend(x = -0.15, y = 0, legend = c("Données publiques, partagées déjà lissées", "Données dé-lissées"), 
          col = c(col452R, colDL), 
          pch = 16, 
          box.col = gray(0, 0), bty = "n", cex = 1)

# 2 HDF
#layout(1)
plotRegC0("Hauts-de-France")


# 3 Plot credits
par(mar = c(0, 0, 0, 0))
plot(0, 0, xlab = "", ylab = "", type = "n", axes = FALSE, xlim = c(-0.1, 1), ylim = c(-1, 1))
text(0, 0, "@flodebarre 

Data:
https://www.data.gouv.fr/fr/datasets/
donnees-de-laboratoires-pour-le-
depistage-indicateurs-sur-les-mutations/

Code: https://github.com/flodebarre/
nouveauCriblage/blob/main/scripts/mutations.Rmd
", adj = 0, cex = 0.8, family = "mono")

# 4 NOR
plotRegC0("Normandie")

# 5 IDF
# 
#layout(1)
plotRegC0("Île-de-France")

# 6 GE
plotRegC0("Grand Est")

# 7 BRE
plotRegC0("Bretagne")

# 8 CVL
plotRegC0("Centre-Val de Loire")

# 9 BFC
plotRegC0("Bourgogne-Franche-Comté")

# 10 PDL
plotRegC0("Pays de la Loire")

# 11 ARA
plotRegC0("Auvergne-Rhône-Alpes")

# 12 PACA
plotRegC0("Provence-Alpes-Côte d'Azur")

# 13 NAQ
plotRegC0("Nouvelle-Aquitaine")

# 14 OCC
plotRegC0("Occitanie")

# 15 COR
plotRegC0("Corse")
```

```{r IDF, eval = FALSE}
layout(1)
plotRegC0("Île-de-France", addNotes = TRUE, ymax = 1, ymin = 0, addLegend = TRUE, scale = "linear")
```

```{r predict, eval = FALSE}

source("projections.R")
```

#### Number tests, delisses

```{r, eval = FALSE}
colCrib <- "#91D900"
colTest <- gray(0.5)

plotCribTest <- function(regname, minDate = "2021-11-15"){
  
  # Get region number
  reg <- names(regs)[which(regs==regname)]
  
  # Load deliss data
  datreg <- read.csv(paste0("../data/deliss_reg-", reg, ".csv"))

  # Case data
  dC <- datCases[which(datCases$cl_age90 == 0 & datCases$reg == reg & datCases$jour >= min(datreg$date2)), ]
  
  datreg <- datreg[datreg$date2 >= minDate, ]
  dC <- dC[dC$jour >= minDate, ]
  
  par(mar = c(3, 3, 3, 3), xpd = TRUE, mgp = c(2.5, 0.5, 0), las = 1)
  lwdd <- 6
  plot(as.Date(dC$jour), dC$P, xlim = as.Date(c(minDate, max(dC$jour))), 
       ylim = c(0, 1.1*max(dC$P)), 
       yaxs = "i", 
       type = "h", lwd = lwdd, lend = 1, 
       col = colTest, frame.plot = FALSE, 
       xlab = "", ylab = "", axes = FALSE)
  points(as.Date(datreg$date2), datreg$nb_C0_dl + datreg$nb_C1_dl, 
         type = "h", lwd = lwdd, col = colCrib, lend = 1)
  axis(2)
  axis(4)
  xx <- seq(as.Date(minDate), as.Date(max(dC$jour)), by = "day")
  axis(1, at = xx, labels = format(xx, "%d/%m"), las = 2, cex.axis = 0.7, lwd = 0)
  
  title(regname)
}


```


```{r NbTestsCribDeliss, fig.width=10, fig.height=13, eval = FALSE}
layout(matrix(1:15, ncol = 3, byrow = TRUE))

# 1 Plot legend
par(mar = c(0, 0, 0, 0))
plot(0, 0, xlab = "", ylab = "", type = "n", axes = FALSE, xlim = c(-0.2, 1), ylim = c(-1, 0.5))
legend(x = -0.15, y = 0, legend = c("Nb de tests positifs du jour", "Nb de tests criblés et interprétables"), 
          col = c(colTest, colCrib), 
          pch = 15, 
          box.col = gray(0, 0), bty = "n", cex = 1.2)

# 2 HDF
#layout(1)
plotCribTest("Hauts-de-France")


# 3 Plot credits
par(mar = c(0, 0, 0, 0))
plot(0, 0, xlab = "", ylab = "", type = "n", axes = FALSE, xlim = c(-0.1, 1), ylim = c(-1, 1))
text(0, 0, "@flodebarre 

Data:
https://www.data.gouv.fr/fr/datasets/
donnees-de-laboratoires-pour-le-
depistage-indicateurs-sur-les-mutations/

Code: https://github.com/flodebarre/
nouveauCriblage/blob/main/scripts/mutations.Rmd
", adj = 0, cex = 0.8, family = "mono")

# 4 NOR
plotCribTest("Normandie")

# 5 IDF
# 
#layout(1)
plotCribTest("Île-de-France")

# 6 GE
plotCribTest("Grand Est")

# 7 BRE
plotCribTest("Bretagne")

# 8 CVL
plotCribTest("Centre-Val de Loire")

# 9 BFC
plotCribTest("Bourgogne-Franche-Comté")

# 10 PDL
plotCribTest("Pays de la Loire")

# 11 ARA
plotCribTest("Auvergne-Rhône-Alpes")

# 12 PACA
plotCribTest("Provence-Alpes-Côte d'Azur")

# 13 NAQ
plotCribTest("Nouvelle-Aquitaine")

# 14 OCC
plotCribTest("Occitanie")

# 15 COR
plotCribTest("Corse")
```

### Departements

```{r}
ymax <- max(1, 1.05*max(dat.Deps$nb_C1 / (dat.Deps$nb_C1 + dat.Deps$nb_C0), na.rm = TRUE))
```

```{r eval = FALSE}
for(dep in sort(unique.noNA(dat.Deps$departement))){
  dat <- dat.Deps[dat.Deps$departement == dep, ]
  plotMut(time = dat$date2, test0 = dat$nb_C0, test1 = dat$nb_C1, col = col452R, thetit = paste0("L452R, ", dep), ymax = ymax)
}
```

```{r eval = FALSE}
ymax <- max(1, 1.05*max(dat.Deps$nb_B1 / (dat.Deps$nb_B1 + dat.Deps$nb_B0), na.rm = TRUE))
for(dep in sort(unique.noNA(dat.Deps$departement))){
  dat <- dat.Deps[dat.Deps$departement == dep, ]
  plotMut(time = dat$date2, test0 = dat$nb_B0, test1 = dat$nb_B1, col = col484Q, thetit = paste0("E484Q, ", dep), ymax = ymax)
}
```


## Variant numbers

### Generic

```{r}
fx <- 0.5

plotVariants <- function(time, test0, test1, pos, tot, population = 10^5, ymax = NA){
  # time: time vector (mid dates if sliding windows)
  # test0: abundances of 0 results in criblage
  # test1: abundances of 1 results in criblage
  # pos: number of positive tests (unaveraged)
  # tot: total number of tests done
  # pop: population size, to express as per 10^5 inhabitants (default value gives absolute numbers)
  # ymax: ymax value on the plot
  
  n <- (test0 + test1)/7 # Sample size; divide by 7 because values are given as sums over 7 days
  p <- (test1/7) / n # Proportion test1
  SE <- sqrt(p * (1-p) / n) # Standard error
  
  # Scaled population
  pop <- population / 10^5
  
  # Positivity rate
  tpos <- pos/tot
  # Dirty trick to get some error on the number of positive tests, using the positivity rate
  SE2 <- sqrt(tpos * (1 - tpos) / tot)
  posmin <- tot * (tpos - 1.96 * SE2)
  posmax <- tot * (tpos + 1.96 * SE2)
  posmin7j <- sliding.window(posmin)
  posmax7j <- sliding.window(posmax)
  
  
  # Check that days are consecutive
  stopifnot(all(as.numeric(diff(time)) == 1))
  
  # Compute sliding window average for positive tests
  pos7j <- sliding.window(pos)
  
  if(is.na(ymax)){
    ymax <- 1.1 * max(pos7j, na.rm = TRUE)/pop
  }
  
  par(xpd = FALSE)
  plot(c(time[1], time), c(0, pos7j/pop), 
       type = "n", axes = FALSE, 
       xlab = "", ylab = "", 
       ylim = c(0, ymax))
  #rect(xleft = time - fx, 
  #     xright = time + fx, 
  #     ybottom = 0, 
  #     ytop = pos7j)
  
  colBorder <- "white"
  
  # Just cases
  rect(xleft = time - fx, 
       xright = time + fx, 
       ybottom = 0, 
       ytop = pos7j/pop, 
       col = gray(0.7), border = NA)
  
  rect(xleft = time - fx, 
       xright = time + fx, 
       ybottom = 0, 
       ytop = pos7j/pop * (1-p), 
       col = colGrad[7], border = colGrad[7])
  
  rect(xleft = time - fx, 
       xright = time + fx, 
       ybottom = pos7j/pop * (1-p), 
       ytop = pos7j/pop, 
       col = colGrad[1], border = colGrad[1])
  
  
  # 95% interval, bottom
  rect(xleft = time - fx, 
       xright = time + fx, 
       ybottom = posmin7j/pop * (1 - p - 1.96*SE), 
       ytop = pos7j/pop * (1 - p), 
       col = colGrad[6], border = NA)
  
  # 95% interval, top
  rect(xleft = time - fx, 
       xright = time + fx, 
       ybottom = pos7j/pop * (1 - p), 
       ytop = posmax7j/pop * (1 - p + 1.96*SE), 
       col = colGrad[2], border = NA)
  
  # 75% interval, bottom
  rect(xleft = time - fx, 
       xright = time + fx, 
       ybottom = posmin7j/pop * (1 - p - 1.15*SE), 
       ytop = pos7j/pop * (1 - p), 
       col = colGrad[5], border = NA)
  
  # 75% interval, top
  rect(xleft = time - fx, 
       xright = time + fx, 
       ybottom = pos7j/pop * (1 - p), 
       ytop = posmax7j/pop * (1 - p + 1.15*SE), 
       col = colGrad[3], border = NA)
  
  # 50% interval
  rect(xleft = time - fx, 
       xright = time + fx, 
       ybottom = posmin7j/pop * (1 - p - 0.68*SE), 
       ytop = posmax7j/pop * (1 - p + 0.68*SE), 
       col = colGrad[4], border = NA)
  
  # Borders
  rect(xleft = time - fx,
       xright = time + fx,
       ybottom = 0,
       ytop = pos7j/pop,
       col = gray(0, 0), border = colBorder, lwd = 0.5)
  
  axis(2, pos = min(time) + 3 - fx, lwd = 0, lwd.ticks = 1, mgp = c(0, 0.3, 0), tck = -0.015)
  axis(4, pos = max(time) - 3 + fx, lwd = 0, lwd.ticks = 1, mgp = c(0, 0.3, 0), tck = -0.015)
  
  xx <- seq(min(time) + 3, max(time) - 3, by = "day")
  axis(1, at = xx, las = 3, labels = format(xx, "%d/%m"), mgp = c(0, 0.2, 0), pos = 0, lwd = 0, cex.axis = 0.8)

}


# Function to plot them by region
plotVariantsReg.C.bypop <- function(region, tit = NA, minDate = "2021-11-12", ymax = NA){
  # region: region name
  # tit: plot title
  # minimum date for the plot (3 days before the desired date, because of 7-day averaging)
  if(is.na(tit)){tit  = region}
  
  dat <- dat.Regions[which(dat.Regions$dateMid >= minDate & dat.Regions$reg_name == region), ]
  
  plotVariants(time = dat$dateMid, 
               test1 = dat$nb_C0, 
               test0 = dat$nb_C1,
               pos = dat$P,
               tot = dat$T, 
               population = unique(dat$pop), 
               ymax = ymax)
  
  title(main = tit)
}
  

plotVariantsReg.D.bypop <- function(region, tit = NA, minDate = "2021-11-12", ymax = NA){
  # region: region name
  # tit: plot title
  # minimum date for the plot (3 days before the desired date, because of 7-day averaging)
  if(is.na(tit)){tit  = region}
  
  dat <- dat.Regions[which(dat.Regions$dateMid >= minDate & dat.Regions$reg_name == region), ]
  
  plotVariants(time = dat$dateMid, 
               test1 = dat$nb_D1, 
               test0 = dat$nb_D0,
               pos = dat$P,
               tot = dat$T, 
               population = unique(dat$pop), 
               ymax = ymax)
  
  title(main = tit)
}

```


### France

```{r figFranceNbC0}
layout(1)
minDate <- "2021-11-12"
dat <- dat.France[which(dat.France$dateMid >= minDate), ]
par(las = 1)
plotVariants(time = dat$dateMid, 
               test1 = dat$nb_C0, 
               test0 = dat$nb_C1,
               pos = dat$P,
               tot = dat$T)
title("France")

```

```{r figFranceNbD1}
layout(1)
par(las = 1)
plotVariants(time = dat$dateMid, 
               test1 = dat$nb_D1, 
               test0 = dat$nb_D0,
               pos = dat$P,
               tot = dat$T)
title("France")

```

### Regions

```{r, fig.width=10, fig.height=15}
dat <- dat.Regions[which(dat.Regions$dateMid >= minDate & dat.Regions$reg_name == "Île-de-France"), ]
tit <- "IDF"

par(las = 1)
plotVariants(time = dat$dateMid, 
               test1 = dat$nb_C0, 
               test0 = dat$nb_C1,
               pos = dat$P,
               tot = dat$T, 
               population = unique(dat$pop))

time <- dat$dateMid
test1 <- dat$nb_C0
test0 <- dat$nb_C1
pos <- dat$P
tot <- dat$T

```


```{r figRegionsMapNbC0, fig.width=7, fig.height=10}
plotVariantsReg <- plotVariantsReg.C.bypop

#
#ix <- which(dat.France$date2 > "2021-11-01")
#plotMut0(dat.France[ix, "date2"], dat.France[ix, "nb_C0"], dat.France[ix, "nb_C1"], col = col452R, thetit = "L452R, France", ymin = 10^-2, ymax = 0.6)

ymaxpic <- 600

layout(matrix(1:15, ncol = 3, byrow = TRUE))
par(las = 1)

# 1 Plot legend
par(mar = c(0, 0, 0, 0))
plot(0, 0, xlab = "", ylab = "", type = "n", axes = FALSE, xlim = c(-0.2, 1), ylim = c(-1, 0.5))
legend(x = -0.15, y = 0.2, legend = c("Variants sans L452R, C0 \n(Omicron, mais aussi B.1.640)", "Variants avec L452R, C1 \n(Delta)", "(Marge d'erreur)"), 
          col = c(colGrad[1], colGrad[7], colGrad[4]), 
          pch = 15, 
          box.col = gray(0, 0), bty = "n", cex = 1, title = "Estimations des nombres de cas quotidiens, 
(pour 100 000 habitants ; moyenne 7 jours)", pt.cex = 2, 
y.intersp = 1.5)

# 2 HDF
#layout(1)
marplot <- c(2, 2, 2, 2)
par(mar = marplot)
plotVariantsReg("Hauts-de-France", ymax = ymaxpic)


# 3 Plot credits
par(mar = c(0, 0, 0, 0))
plot(0, 0, xlab = "", ylab = "", type = "n", axes = FALSE, xlim = c(-0.1, 1), ylim = c(-1, 1))
text(0, 0, paste0("@flodebarre, ", max(dat.France$date2, na.rm = TRUE) + 3, "

Data:
https://www.data.gouv.fr/fr/datasets/
donnees-de-laboratoires-pour-le-
depistage-indicateurs-sur-les-mutations/
and 
https://www.data.gouv.fr/fr/datasets/
donnees-relatives-aux-resultats-des-
tests-virologiques-covid-19/

Code: https://github.com/flodebarre/
nouveauCriblage/blob/main/scripts/mutations.Rmd
"), adj = 0, cex = 0.6, family = "mono")

par(mar = marplot)

# 4 NOR
plotVariantsReg("Normandie", ymax = ymaxpic)

# 5 IDF
# 
#layout(1)
plotVariantsReg("Île-de-France", ymax = ymaxpic)

# 6 GE
plotVariantsReg("Grand Est", ymax = ymaxpic)

# 7 BRE
plotVariantsReg("Bretagne", ymax = ymaxpic)

# 8 CVL
plotVariantsReg("Centre-Val de Loire", ymax = ymaxpic)

# 9 BFC
plotVariantsReg("Bourgogne-Franche-Comté", ymax = ymaxpic)

# 10 PDL
plotVariantsReg("Pays de la Loire", ymax = ymaxpic)

# 11 ARA
plotVariantsReg("Auvergne-Rhône-Alpes", ymax = ymaxpic)

# 12 PACA
plotVariantsReg("Provence-Alpes-Côte d'Azur", ymax = ymaxpic)

# 13 NAQ
plotVariantsReg("Nouvelle-Aquitaine", ymax = ymaxpic)

# 14 OCC
plotVariantsReg("Occitanie", ymax = ymaxpic)

# 15 COR
plotVariantsReg("Corse", ymax = ymaxpic)
```

### Outre Mer

```{r figOutreMerMapNbC0, fig.width=5, fig.height=6}
plotVariantsReg <- plotVariantsReg.C.bypop

#
#ix <- which(dat.France$date2 > "2021-11-01")
#plotMut0(dat.France[ix, "date2"], dat.France[ix, "nb_C0"], dat.France[ix, "nb_C1"], col = col452R, thetit = "L452R, France", ymin = 10^-2, ymax = 0.6)

ymaxpic <- 600

layout(matrix(1:6, ncol = 2, byrow = TRUE))
par(las = 1)

marplot <- c(2, 2, 2, 2)

# 1 Guadeloupe
par(mar = marplot)
plotVariantsReg("Guadeloupe", ymax = ymaxpic)

# 1 Plot legend
par(mar = c(0, 0, 0, 0))
plot(0, 0, xlab = "", ylab = "", type = "n", axes = FALSE, xlim = c(-0.2, 1), ylim = c(-1, 0.5))
legend(x = -0.15, y = 0.2, legend = c("Variants sans L452R, C0 \n(Omicron, mais aussi B.1.640)", "Variants avec L452R, C1 \n(Delta)", "(Marge d'erreur)"), 
          col = c(colGrad[1], colGrad[7], colGrad[4]), 
          pch = 15, 
          box.col = gray(0, 0), bty = "n", cex = 1, title = "Estimations des nombres de cas quotidiens, 
(pour 100 000 habitants ; moyenne 7 jours)", pt.cex = 2, 
y.intersp = 1.5)

# 3 Martinique
par(mar = marplot)
plotVariantsReg("Martinique", ymax = ymaxpic)

# 4 Mayotte
plotVariantsReg("Mayotte", ymax = ymaxpic)

# 5 Guyane
plotVariantsReg("Guyane", ymax = ymaxpic)

# 6 Reunion
plotVariantsReg("La Réunion", ymax = ymaxpic)


```

## Geographic
### L452R 

Source idea map: [Le Monde map](https://www.lemonde.fr/les-decodeurs/article/2020/05/05/coronavirus-age-mortalite-departements-pays-suivez-l-evolution-de-l-epidemie-en-cartes-et-graphiques_6038751_4355770.html) [| archived](https://archive.is/eJ68m)

```{r}
thrp <- 0.15
thrntot <- 30

drawRec <- function(depDat, x, y, dxy, col = col452R, thr.p = thrp, thr.n = thrntot/7, colMaj = col452R.complement){
  # depDat: dataset for this departement
  # x: x position of the bottom left corner
  # y: y position of the bottom left corner
  # dxy: rectangle size c(dx, dy)
  # col: main color
  # thr.p: threshold to plot criblage data, minimum proportion of cases
  # thr.n: threshold in terms of number of tests done
  
  relTime <- as.numeric(depDat$time)/max(as.numeric(depDat$time))
  test0 <- depDat$nb_C0
  test1 <- depDat$nb_C1
  
  denom <- 7
  n <- (test1 + test0) / denom
  p <- test1 / (test1 + test0)
  
  scale.xy <- function(z, z1, z2, zmax = 1){
    # z has to be between 0 and 1
    stopifnot(z >= 0 | z <= 1)
    z1 + (z2 - z1) * z/zmax
  }
  
  # Computation of the confidence interval
  deltaItv <- 1.96 * sqrt(p * (1-p) / n)
  keepPts <- !is.na(deltaItv) & (depDat$tx_crib/100 >= thr.p) & (n >= thr.n)
  
  if(any(keepPts)){
      # Remove points for which the itv cannot be computed
  # and point with not enough criblage
  deltaItv <- deltaItv[keepPts]
  pp <- p[keepPts]
  
  # Color depends on whether main mutation
  if(pp[length(pp)] > 0.5){
    thecol <- colMaj
  }else{
      thecol <- col
  }

  lines(scale.xy(relTime[keepPts], x, x + dxy[1]), scale.xy(pp, y, y + dxy[2]), type = "o", col = thecol, pch = 16, cex = 0.2, lwd = 0.7)
  
  xx <- relTime[keepPts]
  
  polygon(x = scale.xy(c(xx, rev(xx), xx[1]), x, x + dxy[1]), y = scale.xy(c(sapply(pp + deltaItv, min, 1), 
                                                                             sapply(rev(pp - deltaItv), max, 0), 
                                                                             sapply((pp + deltaItv)[1], min, 1)), y, y + dxy[2]), border = NA, col = adjustcolor(thecol, alpha.f = 0.3))
  }
  
}
```

```{r figMapDepL452R, fig.width = 7, fig.height = 9}
geog <- read.csv("../data/position_deps.csv", header = FALSE)
names(geog) <- c("x", "y", "dep", "shortName")
rr <- 2 # Rounding factor

d1 <- c(5.367367157581877, 1.008996513422371)
d2 <- c(6.203498009030808, 1.7266142092327605)
dd <- d2 - d1
ddr <- round(dd,rr)

par(mar = rep(0.2, 4) + c(2, 0, 2, 0))
# Initialize plot with rect positions
plot(c(round(geog$x, rr), round(geog$x, rr) + ddr[1]), c(round(geog$y, rr), round(geog$y, rr) + ddr[2]), type = "n", asp = 1, axes = FALSE, xlab = "", ylab = "")

# Add titles of the plots
text(x = round(geog$x, rr) + ddr[1]/2, y = round(geog$y, rr) + ddr[2], labels = paste0(geog$shortName, "(", geog$dep, ")"), bg = "white", adj = c(0.5, -0.4), cex = 0.45)

for(i in seq_len(nrow(geog))){
  # Draw rectangle
  rect(xleft = round(geog[i, "x"], rr), ybottom = round(geog[i, "y"], rr), xright = round(geog[i, "x"], rr) + ddr[1], ytop = round(geog[i, "y"], rr) + ddr[2], lwd = 0.5, border = gray(0.6))
  
  # Select departement data
  depDat <- dat.Deps[which(dat.Deps$dep == geog[i, "dep"]), ]
  
  # Horizontal line for 0.5
  lines(c(round(geog[i, "x"], rr), round(geog[i, "x"], rr) + ddr[1]), rep(round(geog[i, "y"], rr) + ddr[2]/2, 2), lty = 1, col = gray(0.6), lwd = 0.5)
  
  # Draw curve
  drawRec(depDat, x = round(geog[i, "x"], rr), y = round(geog[i, "y"], rr), dxy = ddr, col = col452R)

#    readline(prompt="Press [enter] to continue")

}


#drawRec(depDat, x = 5.73820184045573, y = 7.01837788404748, dxy = ddr, col = col452R)

minDay <- format(min(dat.Deps$date2), "%d %b")
maxDay <- format(max(dat.Deps$date2), "%d %b")


xP <- 1.34031283936975
yP <- 15.0106959818622
cexLeg <- 0.45
text(x = xP, y = yP, adj = c(1, 0), labels = "0% ", cex = 0.4)
text(x = xP, y = yP + ddr[2], adj = c(1, 0.5), labels = "100% ", cex = cexLeg)

text(x = c(xP, xP + ddr[1]), y = c(yP, yP), adj = c(0.5, 1.5), labels = c(minDay, maxDay), cex = cexLeg)

title("Proportion de L452R")

  mtext("  @flodebarre
  Données : https://www.data.gouv.fr/fr/datasets/donnees-de-laboratoires-pour-le-depistage-indicateurs-sur-les-mutations/
  Code : https://github.com/flodebarre/nouveauCriblage/blob/main/scripts/mutations.Rmd
  Idée carte : Les Decodeurs, Le Monde https://tinyurl.com/carteFRDecLM", side = 1, line = 1, cex = 0.6, col = gray(0.5), adj = 0)
  
cexLegend <- 0.6
legend("topright", legend = c("Proportion L452R, < 50% le dernier jour", "≥ 50% le dernier jour"), cex = cexLegend, bty = "n", col = c(col452R, col452R.complement), lty = 1, pch = 16)
legend("topright", legend = c("", paste0("Données tracées si au moins ", 100*thrp, "% des cas criblés
et au moins ", thrntot, " criblages sur la semaine. 
Itv confiance sur nb crib. moyen 7 derniers jours.")), cex = cexLegend, bty = "n")
```

### Absence L452R 

Source idea map: [Le Monde map](https://www.lemonde.fr/les-decodeurs/article/2020/05/05/coronavirus-age-mortalite-departements-pays-suivez-l-evolution-de-l-epidemie-en-cartes-et-graphiques_6038751_4355770.html) [| archived](https://archive.is/eJ68m)

```{r}
thrp <- 0.125
thrntot <- 30

drawRec0 <- function(depDat, x, y, dxy, col = col452R, thr.p = thrp, thr.n = thrntot/7, colMaj = col452R.complement, scale = "logit", ymin = 1*10^(-2), ymax = 1, yvals = c(0.01, 0.1, 0.5, 0.9, 0.99), ylabels = FALSE){
  # depDat: dataset for this departement
  # x: x position of the bottom left corner
  # y: y position of the bottom left corner
  # dxy: rectangle size c(dx, dy)
  # col: main color
  # thr.p: threshold to plot criblage data, minimum proportion of cases
  # thr.n: threshold in terms of number of tests done
  # scale: type of scale (logit or linear)
  # ymin: minimum y value (natural scale)
  # ymax: maximum y value (natural scale)
  # yvals: values of the horizontal lines
  # ylabels: whether to add ylines labels
  
  relTime <- (as.numeric(depDat$time) - min(as.numeric(depDat$time)))/(max(as.numeric(depDat$time)) - min(as.numeric(depDat$time)))
  test0 <- depDat$nb_C0
  test1 <- depDat$nb_C1
  
  denom <- 7
  n <- (test1 + test0) / denom
  p <- test0 / (test1 + test0)
  
  scale.xy <- function(yv, z1, z2, zmin = 0, zmax = 1){
    # Put y on the (0, 1) scale
    z <- (yv - zmin)/(zmax - zmin)
    # z is between 0 and 1 ; can go beyond with the confidence interval -> crop
    z[z < 0] <- 0
    z[z > 1] <- 1
    # Rescale z on the z1, z2 scale
    z1 + (z2 - z1) * z
  }
  
  # Compute new values on the new scale
  chgScale <- function(Z){
    out <- NA # Initialize output, have NA if scale not properly written
    if(scale == "logit"){
      # Crop values, can be outside of (0, 1) when confidence interval
      pf <- Z
      pf[pf < ymin] <- ymin
      pf[pf > ymax] <- ymax
      # Compute logit
      out <- log(pf /(1-pf)) # Logit scale
#      print("coucou1")
    }
    if(scale == "linear"){
      out <- p # Linear scale, no change
    }
    out
  }

  
  # Computation of the confidence interval
  deltaItv <- 1.96 * sqrt(p * (1-p) / n)
  keepPts <- !is.na(deltaItv) & (depDat$tx_crib/100 >= thr.p) & (n >= thr.n)
  
  if(any(keepPts)){
  #  print("coucou")
      
  # Remove points for which the itv cannot be computed
  # and point with not enough criblage
  deltaItv <- deltaItv[keepPts]
  pp <- p[keepPts]
  rT <- relTime[keepPts]
  
  # Get confidence interval values
  itvm <- pp - deltaItv
  itvM <- pp + deltaItv
  
  # Crop confidence interval values to the plot range
  
  # Color depends on whether main mutation
  if(pp[length(pp)] > 0.5){
    thecol <- colMaj
  }else{
    thecol <- col
  }

#print(scale.xy(rT, x, x + dxy[1]))
#print(pp)
#print(pp - deltaItv)
#print(chgScale(pp - deltaItv))
#print(chgScale)
#print(scale.xy(chgScale(pp - deltaItv), y, y + dxy[2], zmin = chgScale(ymin), zmax = chgScale(ymax)))

  arrows(x0 = scale.xy(rT, x, x + dxy[1]), 
         x1 = scale.xy(rT, x, x + dxy[1]), 
         y0 = scale.xy(chgScale(pp - deltaItv), y, y + dxy[2], zmin = chgScale(ymin), zmax = chgScale(ymax)), 
         y1 = scale.xy(chgScale(pp + deltaItv), y, y + dxy[2], zmin = chgScale(ymin), zmax = chgScale(ymax)), 
         code = 0, 
         lwd = 1, 
         col = adjustcolor(thecol, alpha.f = 0.5), 
         lend = 1)
  
  # Horizontal lines at specific values
  nh <- length(yvals)
  arrows(x0 = scale.xy(rep(0, nh), x, x + dxy[1]), 
         x1 = scale.xy(rep(1, nh), x, x + dxy[1]), 
         y0 = scale.xy(chgScale(yvals), y, y + dxy[2], zmin = chgScale(ymin), zmax = chgScale(ymax)), 
         y1 = scale.xy(chgScale(yvals), y, y + dxy[2], zmin = chgScale(ymin), zmax = chgScale(ymax)), 
         col = gray(0.8), 
         lend = 1, 
         code = 0, 
         lwd= 0.8
         )
  
  # 0.5 more visually striking
  if(is.element(0.5, yvals)){
    arrows(x0 = scale.xy(0, x, x + dxy[1]), 
         x1 = scale.xy(1, x, x + dxy[1]), 
         y0 = scale.xy(chgScale(0.5), y, y + dxy[2], zmin = chgScale(ymin), zmax = chgScale(ymax)), 
         y1 = scale.xy(chgScale(0.5), y, y + dxy[2], zmin = chgScale(ymin), zmax = chgScale(ymax)), 
         col = gray(0.8), 
         lend = 1, 
         code = 0, 
         lwd= 2
         )
  }
  
  # Add labels
  if(ylabels){
    dxx <- 0.1
    text(x = scale.xy(rep(max(rT), nh), x + dxx, x + dxy[1] + dxx), 
         y = scale.xy(chgScale(yvals), y, y + dxy[2], zmin = chgScale(ymin), zmax = chgScale(ymax)), 
         labels = yvals, 
         adj = c(0, 0.5), 
         cex = 0.45)
  }
  
  
#  print(pp)
#  print(chgScale(pp))
#  print(chgScale(ymin))
#  print(chgScale(ymax))

    points(scale.xy(rT, x, x + dxy[1]), 
         scale.xy(yv = chgScale(pp), y, y + dxy[2], zmin = chgScale(ymin), zmax = chgScale(ymax)), 
         type = "p", col = thecol, pch = 16, cex = 0.2, lwd = 0.7)
  
  }
}

# This is only here for testing new stuff quickly
#drawRec0(depDat, x = round(geog[i, "x"], rr), y = round(geog[i, "y"], rr), dxy = ddr, col = col452R)

```

```{r figMapDepAbsL452R, fig.width = 7, fig.height = 9}
geog <- read.csv("../data/position_deps.csv", header = FALSE)
names(geog) <- c("x", "y", "dep", "shortName")
rr <- 2 # Rounding factor

d1 <- c(5.367367157581877, 1.008996513422371)
d2 <- c(6.203498009030808, 1.7266142092327605)
dd <- d2 - d1
ddr <- round(dd,rr)

initDate <- "2021-12-01"
ymin <- 1*10^(-2)
ymax <- 0.9
yvals <- c(0.01, 0.1, 0.5, 0.9)

par(mar = rep(0.2, 4) + c(2, 0, 2, 0))
# Initialize plot with rect positions
plot(c(round(geog$x, rr), round(geog$x, rr) + ddr[1]), c(round(geog$y, rr), round(geog$y, rr) + ddr[2]), type = "n", asp = 1, axes = FALSE, xlab = "", ylab = "")

# Add titles of the plots
text(x = round(geog$x, rr) + ddr[1]/2, y = round(geog$y, rr) + ddr[2], labels = paste0(geog$shortName, "(", geog$dep, ")"), bg = "white", adj = c(0.5, -0.4), cex = 0.45)

for(i in seq_len(nrow(geog))){
  # Draw rectangle
  rect(xleft = round(geog[i, "x"], rr), ybottom = round(geog[i, "y"], rr), xright = round(geog[i, "x"], rr) + ddr[1], ytop = round(geog[i, "y"], rr) + ddr[2], lwd = 0.5, border = gray(0.6))
  
  # Select departement data
  depDat <- dat.Deps[which(dat.Deps$dep == geog[i, "dep"] & dat.Deps$date2 >= initDate), ]
  
  # Horizontal line for 0.5
 #  lines(c(round(geog[i, "x"], rr), round(geog[i, "x"], rr) + ddr[1]), rep(round(geog[i, "y"], rr) + ddr[2]/2, 2), lty = 1, col = gray(0.6), lwd = 0.5)
  
  # Draw curve
  if(geog[i, "dep"] == "75"){
    ylb <- TRUE
  }else{
    ylb <- FALSE
  }
  drawRec0(depDat, x = round(geog[i, "x"], rr), y = round(geog[i, "y"], rr), dxy = ddr, col = col452R, 
           ymin = ymin, ymax = ymax, 
           ylabels = ylb, 
           yvals = yvals)

#    readline(prompt="Press [enter] to continue")

}


#drawRec(depDat, x = 5.73820184045573, y = 7.01837788404748, dxy = ddr, col = col452R)

minDay <- format(as.Date(initDate), "%d %b")
maxDay <- format(max(dat.Deps$dateMid), "%d %b")


# xP <- 1.34031283936975
# yP <- 15.0106959818622
# cexLeg <- 0.45
# text(x = xP, y = yP, adj = c(1, 0), labels = ymin, cex = 0.4)
# text(x = xP, y = yP + ddr[2], adj = c(1, 0.5), labels = ymax, cex = cexLeg)

text(x = c(xP, xP + ddr[1]), y = c(yP, yP), adj = c(0.5, 1.5), labels = c(minDay, maxDay), cex = cexLeg)

title("Absence de L452R, échelle logit")

  mtext(paste0("  @flodebarre, mise à jour ", Sys.Date(), "
  Données : https://www.data.gouv.fr/fr/datasets/donnees-de-laboratoires-pour-le-depistage-indicateurs-sur-les-mutations/
  Code : https://github.com/flodebarre/nouveauCriblage/blob/main/scripts/mutations.Rmd
  Idée carte : Les Decodeurs, Le Monde https://tinyurl.com/carteFRDecLM"), side = 1, line = 1, cex = 0.525, col = gray(0.5), adj = 0, family = "mono")
  
cexLegend <- 0.55
#legend("topright", legend = c("Proportion L452R, < 50% le dernier jour", "≥ 50% le dernier jour"), cex = cexLegend, bty = "n", col = c(col452R, col452R.complement), lty = 1, pch = 16)
legend("topright", legend = c(paste0("Données tracées si au moins ", 100*thrp, "% des cas criblés
et au moins ", thrntot, " criblages sur la semaine. 
Itv confiance sur nb crib. moyen 7 derniers jours.

Attention : 
- les données publiques sont lissées, ce qui atténue le signal
- il y a de moins en moins de criblage dans les données publiques")), cex = cexLegend, bty = "n", adj = c(0, 0))
```

### E484K/Q

```{r}

thrp <- 0.1
thrntot <- 30

drawRec2 <- function(depDat, x, y, dxy, col = col484K, thr.p = thrp, thr.n = thrntot/7, colMaj = col452R.complement){
  # depDat: dataset for this departement
  # x: x position of the bottom left corner
  # y: y position of the bottom left corner
  # dxy: rectangle size c(dx, dy)
  # col: main color
  # thr.p: threshold to plot criblage data, minimum proportion of cases
  # thr.n: threshold in terms of number of tests done
  
  relTime <- as.numeric(depDat$time)/max(as.numeric(depDat$time))
  test0 <- depDat$nb_A0 + depDat$nb_B0
  test1 <- depDat$nb_A1 + depDat$nb_B1
  
  denom <- 7
  n <- (test1 + test0) / denom
  p <- test1 / (test1 + test0)
  
  scale.xy <- function(z, z1, z2){
    # z has to be between 0 and 1
    #stopifnot(z >= 0 | z <= 1)
    z1 + (z2 - z1) * z
  }
  
  # Computation of the confidence interval
  deltaItv <- 1.96 * sqrt(p * (1-p) / n)
  keepPts <- !is.na(deltaItv) & (n/(depDat$nb_pos/denom) >= thr.p) & (n >= thr.n)
  
  if(any(keepPts)){
      # Remove points for which the itv cannot be computed
  # and point with not enough criblage
  deltaItv <- deltaItv[keepPts]
  pp <- p[keepPts]
  
  # Color depends on whether main mutation
  if(pp[length(pp)] > 0.5){
    thecol <- colMaj
  }else{
      thecol <- col
  }

  lines(scale.xy(relTime[keepPts], x, x + dxy[1]), scale.xy(pp, y, y + dxy[2]), type = "o", col = thecol, pch = 16, cex = 0.2, lwd = 0.7)
  
  xx <- relTime[keepPts]
  
  polygon(x = scale.xy(c(xx, rev(xx), xx[1]), x, x + dxy[1]), y = scale.xy(c(sapply(pp + deltaItv, min, 1), 
                                                                             sapply(rev(pp - deltaItv), max, 0), 
                                                                             sapply((pp + deltaItv)[1], min, 1)), y, y + dxy[2]), border = NA, col = adjustcolor(thecol, alpha.f = 0.3))
  }
  
}
```

```{r figMapDepE484, fig.width = 7, fig.height = 9}

par(mar = rep(0.2, 4) + c(2, 0, 2, 0))
# Initialize plot with rect positions
plot(c(round(geog$x, rr), round(geog$x, rr) + ddr[1]), c(round(geog$y, rr), round(geog$y, rr) + ddr[2]), type = "n", asp = 1, axes = FALSE, xlab = "", ylab = "")

# Add titles of the plots
text(x = round(geog$x, rr) + ddr[1]/2, y = round(geog$y, rr) + ddr[2], labels = paste0(geog$shortName, "(", geog$dep, ")"), bg = "white", adj = c(0.5, -0.4), cex = 0.45)

for(i in seq_len(nrow(geog))){
  # Draw rectangle
  rect(xleft = round(geog[i, "x"], rr), ybottom = round(geog[i, "y"], rr), xright = round(geog[i, "x"], rr) + ddr[1], ytop = round(geog[i, "y"], rr) + ddr[2], lwd = 0.5, border = gray(0.6))
  
  # Select departement data
  depDat <- dat.Deps[which(dat.Deps$dep == geog[i, "dep"]), ]
  
  # Horizontal line for 0.5
  lines(c(round(geog[i, "x"], rr), round(geog[i, "x"], rr) + ddr[1]), rep(round(geog[i, "y"], rr) + ddr[2]/2, 2), lty = 1, col = gray(0.6), lwd = 0.5)
  
  # Draw curve
  drawRec2(depDat, x = round(geog[i, "x"], rr), y = round(geog[i, "y"], rr), dxy = ddr, col = col484K)

#    readline(prompt="Press [enter] to continue")

}


#drawRec(depDat, x = 5.73820184045573, y = 7.01837788404748, dxy = ddr, col = col452R)

minDay <- format(min(dat.Deps$date2), "%d %b")
maxDay <- format(max(dat.Deps$date2), "%d %b")


xP <- 1.34031283936975
yP <- 15.0106959818622
cexLeg <- 0.45
text(x = xP, y = yP, adj = c(1, 0), labels = "0% ", cex = 0.4)
text(x = xP, y = yP + ddr[2], adj = c(1, 0.5), labels = "100% ", cex = cexLeg)

text(x = c(xP, xP + ddr[1]), y = c(yP, yP), adj = c(0.5, 1.5), labels = c(minDay, maxDay), cex = cexLeg)

title("Proportion de E484K/Q")

  mtext("  @flodebarre
  Données : https://www.data.gouv.fr/fr/datasets/donnees-de-laboratoires-pour-le-depistage-indicateurs-sur-les-mutations/
  Code : https://github.com/flodebarre/nouveauCriblage/blob/main/scripts/mutations.Rmd
  Idée carte : Les Decodeurs, Le Monde https://tinyurl.com/carteFRDecLM", side = 1, line = 1, cex = 0.6, col = gray(0.5), adj = 0)
  
cexLegend <- 0.6
legend("topright", legend = c("Proportion E484K/Q, < 50% le dernier jour", "≥ 50% le dernier jour"), cex = cexLegend, bty = "n", col = c(col484K, col452R.complement), lty = 1, pch = 16)
legend("topright", legend = c("", paste0("Données tracées si au moins ", 100*thrp, "% des cas criblés
et au moins ", thrntot, " criblages sur la semaine. 
Itv confiance sur nb crib. moyen 7 derniers jours.")), cex = cexLegend, bty = "n")
```

