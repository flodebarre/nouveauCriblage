---
title: "Mutations"
author: "FD"
output: 
  html_document: 
      code_folding: hide
      toc: TRUE
      toc_float: TRUE
      self_contained: no
editor_options:
  chunk_output_type: console
---

Warning: The structure of the public datasets has changed, and I am updating this code. Currently, it does not compile if you try to knit it, you need to evaluate it bit by bit (I stopped after "Specific examples"). 

```{r, eval=FALSE}
rm(list = ls()) # I don't care what you think
for(i in dev.list()) dev.off()
setwd("scripts/")
```

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


Source of the data:  
<https://www.data.gouv.fr/fr/datasets/donnees-de-laboratoires-pour-le-depistage-indicateurs-sur-les-mutations/>

# Initializations

```{r}
# Whether to download the data
dlData <- TRUE
```


```{r}
# Set colors
library(RColorBrewer)
colMut <- brewer.pal(n = 8, name = "Dark2")

col484K <- colMut[1]
col484Q <- colMut[2]
col452R <- colMut[3]
colD <- colMut[4]
colAC <- colMut[5]

colTotCrib <- gray(0)#colMut[8]
colTot <- colMut[7]

col452R.complement <- "#b37570"
colDL <- "#FFD390" # Données délissées
```

```{r}
unique.noNA <- function(x){
  unique(x[!is.na(x)])
}
```

# Load data 

## Test data

```{r}
# OLD URLS
URL_Deps_old <- "https://www.data.gouv.fr/fr/datasets/r/4d3e5a8b-9649-4c41-86ec-5420eb6b530c"
URL_Regions_old <- "https://www.data.gouv.fr/fr/datasets/r/5ff0cad6-f150-47ea-a4e0-57e354c1b2a4"
URL_France_old <- "https://www.data.gouv.fr/fr/datasets/r/848debc4-0e42-4e3b-a176-afc285ed5401"

# NEW URLS
URL_Regions <- "https://www.data.gouv.fr/fr/datasets/r/9ed7f76c-09bc-43fb-997a-a1733faa6e8b"
URL_France <- "https://www.data.gouv.fr/fr/datasets/r/7eade8d7-f79a-4c7f-8579-51f3f7104cfb"
URL_Deps <- NA
```

```{r}
# Needed to be done only once

# download.file(URL_France_old, 
#                 destfile="../data/muts_France_old.csv",
#                 method="curl",
#                 extra='-L')
# download.file(URL_Regions_old, 
#                 destfile="../data/muts_Regions_old.csv",
#                 method="curl",
#                 extra='-L')
# 
# download.file(URL_Deps_old, 
#                 destfile="../data/muts_Deps_old.csv",
#                 method="curl",
#                 extra='-L')

dat.France.old <- read.csv("../data/muts_France_old.csv", sep = ";", stringsAsFactors = FALSE)
dat.Regions.old <- read.csv("../data/muts_Regions_old.csv", sep = ";", stringsAsFactors = FALSE)
dat.Deps.old <- read.csv("../data/muts_Deps_old.csv", sep = ";", stringsAsFactors = FALSE)

```

```{r}
# Download files from repo
# Need to use extra option to follow the redirection

if(dlData){
  download.file(URL_France, 
                destfile="../data/muts_France.csv",
                method="curl",
                extra='-L')
  download.file(URL_Regions, 
                destfile="../data/muts_Regions.csv",
                method="curl",
                extra='-L')
  if(!is.na(URL_Deps)){
    download.file(URL_Deps, 
                destfile="../data/muts_Deps.csv",
                method="curl",
                extra='-L')
  }
}


system("git add ../data/muts_*.csv")
system("git commit -m 'update data'")


dat.France.new <- read.csv("../data/muts_France.csv", sep = ";", stringsAsFactors = FALSE)
dat.Regions.new <- read.csv("../data/muts_Regions.csv", sep = ";", stringsAsFactors = FALSE)

if(!is.na(URL_Deps)){
  dat.Deps.new <- read.csv("../data/muts_Deps.csv", sep = ";", stringsAsFactors = FALSE)
}


```


## Geographic data

### Regions 

```{r}
# Codes regions
URL <- "https://www.data.gouv.fr/en/datasets/r/34fc7b52-ef11-4ab0-bc16-e1aae5c942e7"
dataFile <- "../data/coderegions.csv"

if(!file.exists(dataFile)){
  download.file(URL, dataFile)
}

codesRegions <- read.csv(dataFile, sep = ",", stringsAsFactors = FALSE)

# Turn into dictionary
regs <- codesRegions$nom_region
names(regs) <- as.character(codesRegions$code_region)

# Add region name
dat.Regions.new$reg_name <- regs[as.character(dat.Regions.new$reg)]

unique(dat.Regions.new$reg_name)
unique(dat.Regions.new[which(is.na(dat.Regions.new$reg_name)), "reg"])

```


### Departments

```{r}
# Add name
deps <- read.csv("../data/departement2020.csv", stringsAsFactors = FALSE)
# Turn into dictionnary
dps <- deps$libelle
names(dps) <- as.character(deps$dep)

if(!is.na(URL_Deps)){
  dat.Deps$departement <- dps[as.character(dat.Deps$dep)]

  unique(dat.Deps$departement)
  
  unique(dat.Deps[which(is.na(dat.Deps$departement)), "dep"])
  
  # 977 Saint-Barthélemy, 978 Saint-Martin
}

```

## Combine the old and new datasets

Useful functions

```{r}
# Plot colums to check that things are done alright
compare.xy <- function(dat, col, addCombined = TRUE){
   # dat: dataset
   # col: column
  par(las = 1, xpd = TRUE)
  plot(dat[, paste0(col, ".x")], xlab = "jours", ylab = "", main = col)
  points(dat[, paste0(col, ".y")], col = 2, pch = 0, cex = 0.7)
  
  if(addCombined){
    points(dat[, col], pch = 2, col = 3)
    legend("topleft", col = c(1, 2, 3), pch = c(1, 0, 2), legend = c("new", "old", "combined"), bty = "n")
  }else{
    legend("topleft", col = c(1, 2), pch = c(1, 0), legend = c("new", "old"), bty = "n")
  }
  par(xpd = FALSE)
}

# Sum columns, in spite of NAs
computeSum <- function(dat, col){
  tmpx <- dat[, paste0(col, ".x")]
  tmpy <- dat[, paste0(col, ".y")]
  
  # Set NAs to 0
  tmpx[is.na(tmpx)] <- 0
  tmpy[is.na(tmpy)] <- 0
  
  # Return sum
  tmpx + tmpy
}
```

France

```{r mergeFrance}
tmp.France <- merge(dat.France.new, dat.France.old, all = TRUE, by = c("fra", "semaine"))
dim(dat.France.new)
dim(dat.France.old)
dim(tmp.France)
head(tmp.France)

# nb_crib
tmp.France$nb_crib <- computeSum(tmp.France, "nb_crib")
compare.xy(tmp.France, "nb_crib")

# nb_pos
tmp.France$nb_pos <- tmp.France$nb_pos.x # New ones for times >= 2021-01-06
tmp.France[is.na(tmp.France$nb_pos), "nb_pos"] <- tmp.France[is.na(tmp.France$nb_pos), "nb_pos.y"] # Old ones
compare.xy(tmp.France, "nb_pos")

# A0
tmp.France$nb_A0 <- computeSum(tmp.France, "nb_A0")
compare.xy(tmp.France, "nb_A0")

# A1
tmp.France$nb_A1 <- computeSum(tmp.France, "nb_A1")
compare.xy(tmp.France, "nb_A1")

# C0
tmp.France$nb_C0 <- computeSum(tmp.France, "nb_C0")
compare.xy(tmp.France, "nb_C0")

# C1
tmp.France$nb_C1 <- computeSum(tmp.France, "nb_C1")
compare.xy(tmp.France, "nb_C1")
```

Regions

```{r mergeRegions}
tmp.Regions <- merge(dat.Regions.new, dat.Regions.old, all = TRUE, by = c("reg", "semaine"))
dim(dat.Regions.new)
dim(dat.Regions.old)
dim(tmp.Regions)
head(tmp.Regions)
head(dat.Regions.new)


# nb_crib
tmp.Regions$nb_crib <- computeSum(tmp.Regions, "nb_crib")
compare.xy(tmp.Regions, "nb_crib")

# nb_pos
tmp.Regions$nb_pos <- tmp.Regions$nb_pos.x # New ones for times >= 2021-01-06
tmp.Regions[is.na(tmp.Regions$nb_pos), "nb_pos"] <- tmp.Regions[is.na(tmp.Regions$nb_pos), "nb_pos.y"] # Old ones
compare.xy(tmp.Regions, "nb_pos")

# A0
tmp.Regions$nb_A0 <- computeSum(tmp.Regions, "nb_A0")
compare.xy(tmp.Regions, "nb_A0")

# A1
tmp.Regions$nb_A1 <- computeSum(tmp.Regions, "nb_A1")
compare.xy(tmp.Regions, "nb_A1")

# C0
tmp.Regions$nb_C0 <- computeSum(tmp.Regions, "nb_C0")
compare.xy(tmp.Regions, "nb_C0")

# C1
tmp.Regions$nb_C1 <- computeSum(tmp.Regions, "nb_C1")
compare.xy(tmp.Regions, "nb_C1")
```

Departements

```{r mergeDeps}
if(!is.na(URL_Deps)){
  tmp.Deps <- merge(dat.Deps.new, dat.Deps.old, all = TRUE, by = c("dep", "semaine"))
  dim(dat.Deps.new)
  dim(dat.Deps.old)
  dim(tmp.Deps)
  head(tmp.Deps)
  head(dat.Regions.new)
  
  
  # nb_crib
  tmp.Deps$nb_crib <- computeSum(tmp.Deps, "nb_crib")
  compare.xy(tmp.Deps, "nb_crib")
  
  # nb_pos
  tmp.Deps$nb_pos <- tmp.Deps$nb_pos.x # New ones for times >= 2021-01-06
  tmp.Deps[is.na(tmp.Deps$nb_pos), "nb_pos"] <- tmp.Deps[is.na(tmp.Deps$nb_pos), "nb_pos.y"] # Old ones
  compare.xy(tmp.Deps, "nb_pos")
  
  # A0
  tmp.Deps$nb_A0 <- computeSum(tmp.Deps, "nb_A0")
  compare.xy(tmp.Deps, "nb_A0")
  
  # A1
  tmp.Deps$nb_A1 <- computeSum(tmp.Deps, "nb_A1")
  compare.xy(tmp.Deps, "nb_A1")
  
  # C0
  tmp.Deps$nb_C0 <- computeSum(tmp.Deps, "nb_C0")
  compare.xy(tmp.Deps, "nb_C0")
  
  # C1
  tmp.Deps$nb_C1 <- computeSum(tmp.Deps, "nb_C1")
  compare.xy(tmp.Deps, "nb_C1")

}else{
  tmp.Deps <- dat.Deps.old
}

```


Rename data

```{r}
dat.France <- tmp.France
dat.Regions <- tmp.Regions
dat.Deps <- tmp.Deps
```

## Clean data

```{r}
# Format date
dat.France$date1 <- as.Date(substring(dat.France$semaine, 1, 10))
dat.France$date2 <- as.Date(substring(dat.France$semaine, 12, 21))

# Mid-interval date
dat.France$dateMid <- dat.France$date2 - 3

# Rewrite time as days since beginning of the data
dat.France$time <- dat.France$dateMid - min(dat.France$date2)


# Format date
dat.France.old$date1 <- as.Date(substring(dat.France.old$semaine, 1, 10))
dat.France.old$date2 <- as.Date(substring(dat.France.old$semaine, 12, 21))

# Mid-interval date
dat.France.old$dateMid <- dat.France.old$date2 - 3

```


```{r}
# Format date
dat.Regions$date1 <- as.Date(substring(dat.Regions$semaine, 1, 10))
dat.Regions$date2 <- as.Date(substring(dat.Regions$semaine, 12, 21))
# Rewrite time as days since beginning of the data
dat.Regions$time <- dat.Regions$date2 - min(dat.Regions$date2)

# Mid-interval date
dat.Regions$dateMid <- dat.Regions$date2 - 3


# Format date
dat.Regions.old$date1 <- as.Date(substring(dat.Regions.old$semaine, 1, 10))
dat.Regions.old$date2 <- as.Date(substring(dat.Regions.old$semaine, 12, 21))
# Mid-interval date
dat.Regions.old$dateMid <- dat.Regions.old$date2 - 3

```


```{r}
if(!is.na(URL_Deps)){
  # Format date
  dat.Deps$date1 <- as.Date(substring(dat.Deps$semaine, 1, 10))
  dat.Deps$date2 <- as.Date(substring(dat.Deps$semaine, 12, 21))
  # Rewrite time as days since beginning of the data
  dat.Deps$time <- dat.Deps$date2 - min(dat.Deps$date2)
  
  # Mid-interval date
  dat.Deps$dateMid <- dat.Deps$date2 - 3 
}


# Format date
dat.Deps.old$date1 <- as.Date(substring(dat.Deps.old$semaine, 1, 10))
dat.Deps.old$date2 <- as.Date(substring(dat.Deps.old$semaine, 12, 21))
# Mid-interval date
dat.Deps.old$dateMid <- dat.Deps.old$date2 - 3 

```




## Consistency checks 

```{r, eval = FALSE}

testDat <- function(dat){
  # Check number of genotypied tests
  testTotA <- sum(dat$nb_crib != (dat$nb_A0+ dat$nb_A1))
  testTotB <- sum(dat$nb_crib != (dat$nb_B0+ dat$nb_B1))
  testTotC <- sum(dat$nb_crib != (dat$nb_C0+ dat$nb_C1))
  
  # Test proportions of positive genotyping tests
  # nb of digits in the result varies across datasets
  if(all(dat$tx_A1 == round(dat$tx_A1, 1))){nDigits <- 1}else{nDigits <- 2}
  testA <- sum(dat$tx_A1 != round(dat$nb_A1 / (dat$nb_A0 + dat$nb_A1)*100, nDigits), na.rm = TRUE)
  testB <- sum(dat$tx_B1 != round(dat$nb_B1 / (dat$nb_B0 + dat$nb_B1)*100, nDigits), na.rm = TRUE)
  testC <- sum(dat$tx_C1 != round(dat$nb_C1 / (dat$nb_C0 + dat$nb_C1)*100, nDigits), na.rm = TRUE)
  
  testCrib <- sum(round(dat$tx_crib / 100 * dat$nb_pos) != round(dat$nb_crib))
  
  # Return outcome
  c(nrow(dat), testCrib, testTotA, testTotB, testTotB, testA, testB, testC)
}

testDat(dat.France)
testDat(dat.Regions)
if(!is.na(URL_Deps)){
  testDat(dat.Deps)
}

```

# (tmp Extractions)

```{r, eval = FALSE}
tmp <- dat.Regions[which(dat.Regions$reg_name == "Île-de-France"), ]

# dim(tmp)
write.csv(tmp, file = "../data/extractionIDF.csv", col.names = NULL)
```

# Plots 

## Numbers of tests

```{r}
plotNbCrib <- function(dat, quot = TRUE, addLegend = TRUE, tp = "l", lwd = 1.5){
  # dat: dataset to be plotted
  # quot: boolean to decide whether to plot the daily values (averaged over 7 days) [TRUE], or the sum over the last 7 days [FALSE]
  # addLegend: whether to add plot legend
  # tp: line type
  if(quot){denom <- 7}else{denom <- 1}
  par(las = 1)
  par(mar = c(2, 4, 3, 4))
  plot(as.Date(dat$dateMid), dat$nb_pos / denom, ylim = c(0, 1.05*max(dat$nb_pos / denom, na.rm = TRUE)), yaxs = "i", 
       type = tp, pch = 16, col = colTot, 
       lwd = lwd, 
       frame.plot = FALSE, 
       xlab = "", ylab = "")
  
  lines(as.Date(dat$dateMid), dat$nb_crib / denom, type = tp, pch = 16, col = colTotCrib)
  
  if(addLegend){
    legend(x = "topright", legend = c("Nb tests positifs", "Nb tests criblés", "Nb tests interprétables E484K", "Nb tests interprétables E484Q", "Nb tests interprétables L452R", "Nb tests interprétables colonne D", "Nb tests interprétables AC"), 
         col = c(colTot, colTotCrib, col484K, col484Q, col452R, colD, colAC), 
         #pch = 16, 
         lty = 1, box.col = gray(0, 0), bty = "n", 
         lwd = lwd)
  }
  
  lines(as.Date(dat$dateMid), (dat$nb_A0 + dat$nb_A1) / denom, type = tp, pch = 16, col = col484K, lwd = lwd)
  lines(as.Date(dat$dateMid), (dat$nb_B0 + dat$nb_B1) / denom, type = tp, pch = 16, col = col484Q, lwd = lwd)
  lines(as.Date(dat$dateMid), (dat$nb_C0 + dat$nb_C1) / denom, type = tp, pch = 16, col = col452R, lwd = lwd)
  lines(as.Date(dat$dateMid), (dat$nb_D0 + dat$nb_D1) / denom, type = tp, pch = 16, col = colD, lwd = lwd)
  lines(as.Date(dat$dateMid), (dat$nb_A01C01) / denom, type = tp, pch = 16, col = colAC, lwd = lwd)
  
  axis(4)
}
```

```{r}
plotTauxCrib <- function(dat){
  par(las = 1)
  par(mar = c(2, 4, 3, 4))
  plot(dat$dateMid, 100*dat$nb_crib / dat$nb_pos, ylim = c(0, 100), lwd = 3, col = gray(0.3), frame.plot = FALSE, 
       xlab = "", ylab = "", yaxs = "i", type = "p", pch = 16)
  # Show final point
  i <- which(dat$dateMid == max(dat$dateMid, na.rm = TRUE))
  points(dat$dateMid[i], 100*(dat$nb_crib / dat$nb_pos)[i], col = "red", pch = 16)
  axis(4)
}
```


```{r NbCribFrance}
plotNbCrib(dat.France)
title(main = "France")
```


```{r NbCribRegions}
# Plot all regions in single plots
# for(reg in unique.noNA(dat.Regions$reg_name)){
#   dat <- dat.Regions[dat.Regions$reg_name == reg, ]
#   plotNbCrib(dat, addLegend = FALSE)
#   title(main = reg)
# }
```


```{r}
# Function to plot one region
plotReg <- function(reg){
  dat <- dat.Regions[dat.Regions$reg_name == reg, ]
  plotNbCrib(dat, addLegend = FALSE)
  title(main = reg)
}

# Function to plot one region
plotRegTx <- function(reg){
  dat <- dat.Regions[dat.Regions$reg_name == reg & dat.Regions$dateMid > "2021-11-01", ]
  plotTauxCrib(dat)
  title(main = reg)
}

#[1] "Auvergne-Rhône-Alpes"       "Hauts-de-France"            "Provence-Alpes-Côte d'Azur" "Grand Est"                 
# [5] "Occitanie"                  "Normandie"                  "Nouvelle-Aquitaine"         "Centre-Val de Loire"       
# [9] "Corse"                      "Bourgogne-Franche-Comté"    "Bretagne"                   "Pays de la Loire"          
#[13] "Île-de-France"              "Guadeloupe"                 "Martinique"                 "Guyane"                 
#[17] "La Réunion"                 "Mayotte" 
```

```{r figRegionsMapNBCriblage, fig.width=10, fig.height=10}

layout(matrix(1:15, ncol = 3, byrow = TRUE))

# 1 Plot legend
par(mar = c(0, 0, 0, 0))

    
plot(0, 0, xlab = "", ylab = "", type = "n", axes = FALSE, xlim = c(-0.2, 1), ylim = c(-1, 0.5))
legend(x = 0, y = 0, legend = c("Nb tests positifs", "Nb tests criblés", "Nb tests interprétables E484K", "Nb tests interprétables E484Q", "Nb tests interprétables L452R", "Nb tests interprétables colonne D", "Nb tests interprétables AC"), 
         col = c(colTot, colTotCrib, col484K, col484Q, col452R, colD, colAC), 
         #pch = 16, 
         lty = 1, box.col = gray(0, 0), bty = "n", cex = 1)

# 2 HDF
plotReg("Hauts-de-France")

# 3 Plot credits
par(mar = c(0, 0, 0, 0))
plot(0, 0, xlab = "", ylab = "", type = "n", axes = FALSE, xlim = c(-0.1, 1), ylim = c(-1, 1))
text(0, 0, "@flodebarre 

Data:
https://www.data.gouv.fr/fr/datasets/
donnees-de-laboratoires-pour-le-
depistage-indicateurs-sur-les-mutations/

Code: https://github.com/flodebarre/
nouveauCriblage/blob/main/scripts/mutations.Rmd
", adj = 0, cex = 0.8, family = "mono")

# 4 NOR
plotReg("Normandie")

# 5 IDF
plotReg("Île-de-France")

# 6 GE
plotReg("Grand Est")

# 7 BRE
plotReg("Bretagne")

# 8 CVL
plotReg("Centre-Val de Loire")

# 9 BFC
plotReg("Bourgogne-Franche-Comté")

# 10 PDL
plotReg("Pays de la Loire")

# 11 ARA
plotReg("Auvergne-Rhône-Alpes")

# 12 PACA
plotReg("Provence-Alpes-Côte d'Azur")

# 13 NAQ
plotReg("Nouvelle-Aquitaine")

# 14 OCC
plotReg("Occitanie")

# 15 COR
plotReg("Corse")
#[1] "Auvergne-Rhône-Alpes"       "Hauts-de-France"            "Provence-Alpes-Côte d'Azur" "Grand Est"                 
# [5] "Occitanie"                  "Normandie"                  "Nouvelle-Aquitaine"         "Centre-Val de Loire"       
# [9] "Corse"                      "Bourgogne-Franche-Comté"    "Bretagne"                   "Pays de la Loire"  

```

```{r figRegionsMapTauxCriblage, fig.width=10, fig.height=10}

layout(matrix(1:15, ncol = 3, byrow = TRUE))

# 1 Plot legend
par(mar = c(0, 0, 0, 0))
plot(0, 0, xlab = "", ylab = "", type = "n", axes = FALSE, xlim = c(-0.2, 1), ylim = c(-1, 0.5))
text(0, 0, "Pourcentage de tests criblés", adj = c(0, 0), cex = 1.3)
text(0, 0, "(les données publiques sont déjà lissées, 
ce qui 'arrondit' les changements brutaux)", adj = c(0, 2))
# 2 HDF
plotRegTx("Hauts-de-France")

# 3 Plot credits
par(mar = c(0, 0, 0, 0))
plot(0, 0, xlab = "", ylab = "", type = "n", axes = FALSE, xlim = c(-0.1, 1), ylim = c(-1, 1))
text(0, 0, "@flodebarre 

Data:
https://www.data.gouv.fr/fr/datasets/
donnees-de-laboratoires-pour-le-
depistage-indicateurs-sur-les-mutations/

Code: https://github.com/flodebarre/
nouveauCriblage/blob/main/scripts/mutations.Rmd
", adj = 0, cex = 0.8, family = "mono")

# 4 NOR
plotRegTx("Normandie")

# 5 IDF
plotRegTx("Île-de-France")

# 6 GE
plotRegTx("Grand Est")

# 7 BRE
plotRegTx("Bretagne")

# 8 CVL
plotRegTx("Centre-Val de Loire")

# 9 BFC
plotRegTx("Bourgogne-Franche-Comté")

# 10 PDL
plotRegTx("Pays de la Loire")

# 11 ARA
plotRegTx("Auvergne-Rhône-Alpes")

# 12 PACA
plotRegTx("Provence-Alpes-Côte d'Azur")

# 13 NAQ
plotRegTx("Nouvelle-Aquitaine")

# 14 OCC
plotRegTx("Occitanie")

# 15 COR
plotRegTx("Corse")
#[1] "Auvergne-Rhône-Alpes"       "Hauts-de-France"            "Provence-Alpes-Côte d'Azur" "Grand Est"                 
# [5] "Occitanie"                  "Normandie"                  "Nouvelle-Aquitaine"         "Centre-Val de Loire"       
# [9] "Corse"                      "Bourgogne-Franche-Comté"    "Bretagne"                   "Pays de la Loire"  

```


## Proportions / Nb tests

```{r}
plotMut <- function(time, test0, test1, col, thetit, ymax = 1, quot = TRUE, add = FALSE){
  # quot: boolean to decide whether to plot the daily values (averaged over 7 days) [TRUE], or the sum over the last 7 days [FALSE]
  
  if(quot){denom <- 7}else{denom <- 1}
  n <- (test1 + test0) / denom
  p <- test1 / (test1 + test0)
  
  # Computation of the confidence interval
  deltaItv <- 1.96 * sqrt(p * (1-p) / n)
  keepPts <- !is.na(deltaItv) 
  # Remove points for which the itv cannot be computed
  deltaItv <- deltaItv[keepPts]
  pp <- p[keepPts]
  xx <- base::as.Date(time)[keepPts]

  par(mar = c(5, 4, 4, 4))
  par(las = 1)
  par(xpd = TRUE)
  if(!add){
    plot(as.Date(time), p, ylim = c(0, ymax), frame.plot = FALSE, 
     xlab = "", ylab = "p", yaxs = "i", xaxs = "i", 
     type = "p", col = col, pch = 16)
    par(xpd = FALSE)
  mtext("  Parmi les n(t) tests interprétables recherchant la mutation
  Intervalle de confiance binomial sur ce nombre de tests n(t)", side = 3, cex = 0.6, adj = 0, line = -1)
  mtext("date", line = 2, side = 1)  
  axis(4)
  # Add graduation
  for(i in seq(0, 1, by = 0.1)){
    abline(h = i, col = gray(0.9), lwd = 1.1)
  }
  for(i in seq(0.05, 0.95, by = 0.1)){
    abline(h = i, col = gray(0.9), lwd = 0.8)
  }
  
  mtext("Données : https://www.data.gouv.fr/fr/datasets/donnees-de-laboratoires-pour-le-depistage-indicateurs-sur-les-mutations/
Code : https://github.com/flodebarre/nouveauCriblage", side = 1, line = 3.5, cex = 0.6, col = gray(0.5), adj = 0, family = "mono")

  title(main = thetit)

  }else{ # Else of add
    par(xpd = TRUE)
    points(as.Date(time), p,  
     type = "p", col = col, pch = 16)
  }
  arrows(x0 = xx, x1 = xx, 
         y0 = pp - deltaItv, y1 = pp + deltaItv, 
         col = col, lwd = 1, code = 0)
#  polygon(x = c(xx, rev(xx), xx[1]), y = c(pp + deltaItv, rev(pp - deltaItv), (pp + deltaItv)[1]), border = NA, col = adjustcolor(col, alpha.f = 0.3))
  par(xpd = FALSE)
  print(p[length(p)])
}
```


```{r}
plotMut0 <- function(time, test0, test1, col, thetit, ymin = 10^-6, ymax = 1 - 10^-6, quot = TRUE, scale = "logit", addNotes = TRUE, addDeliss = FALSE, timedl, test0dl, test1dl, coldl = colDL, addLegend = FALSE){
  # -- here showing n0/(n0+n1) --
  # time: vector of values of times of sample collection
  # test0: vector of numbers of tests with value 0
  # test1: vector of numbers of tests with value 1
  # col: color used for the plot
  # thetit: title of the plot
  # ymin: min y value
  # ymax: max y value
  # quot: (quotidien) boolean to decide whether to plot the daily values (averaged over 7 days) [TRUE], or the sum over the last 7 days [FALSE]
  # scale: "logit" or "linear"
  # addNotes: whether to show warning notes on the plot
  # addDeliss: whether to add data délissées (if available)
  # timedl: time values of the délissées data
  # test0dl: C0 values délissées
  # test1dl: C1 values délissées
  # coldl: color for the délissées data
  # addLegend: whether to add legend
  if(quot){denom <- 7}else{denom <- 1}
  n <- (test1 + test0) / denom
  p <- test0 / (test1 + test0)
  
  # Computation of the confidence interval
  deltaItv <- 1.96 * sqrt(p * (1-p) / n)
  keepPts <- !is.na(deltaItv) 
  # Remove points for which the interval cannot be computed
  deltaItv <- deltaItv[keepPts]
  pp <- p[keepPts]
  
  dxx <- 0 # Number of days to be added (depends on whether data délissées are used)
  
  cexL <- 1 # Point size of lissées data
  if(addDeliss){cexL <- 1.2}
  
  if(addDeliss){
    dxx <- 3 # 3 more days if data délissées are added
    ndl <- (test1dl + test0dl)
    pdl <- test0dl / (test0dl + test1dl)
    deltaItvdl <- 1.96 * sqrt(pdl * (1-pdl) / ndl)
    keepPtsdl <- !is.na(deltaItvdl) 
    # Remove points for which the interval cannot be computed
    deltaItvdl <- deltaItvdl[keepPtsdl]
    ppdl <- pdl[keepPtsdl]
  }

  # Compute new values on the new scale
  changeScale <- function(p, confInt = FALSE){
    out <- NA # Initialize output, have NA if scale not properly written
    if(scale == "logit"){
      # Make sure that p is between 0 and 1 (can be different with conf int)
      p[p < ymin] <- max(0, 0.5*ymin)
      p[p > ymax] <- 2*ymax
      
      out <- log(p /(1-p)) # Logit scale
    }
    if(scale == "linear"){
      out <- p # Linear scale, no change
    }
    out
  }

  par(mar = c(5, 4, 4, 4))
  par(las = 1, mgp = c(2.5, 0.3, 0), tck = -0.01)
  
  xmin <- min(as.Date(time), na.rm = TRUE)
  xmax <- max(as.Date(time), na.rm = TRUE)
  if(addDeliss){
     xmax <- xmax + 3
  }
  
  plot(as.Date(time), changeScale(p), 
       ylim = c(changeScale(ymin), changeScale(ymax)), 
       xlim = c(xmin, xmax),
       frame.plot = FALSE, 
       xlab = "", ylab = "", 
       col = col, pch = 16, 
       axes = FALSE, 
       yaxs = "i", type = "n")
  
  
    # Add graduations
  if(scale == "linear"){
    colGrad <- gray(0.85)
    for(i in seq(0, 1, by = 0.1)){
      abline(h = i, col = colGrad, lwd = 1.2)
    }
    for(i in seq(0.05, 0.95, by = 0.1)){
#      abline(h = i, col = colGrad, lwd = 0.8)
    }
      abline(h = 0.5, col = colGrad, lwd = 3)
  }

  
  # if(addNotes){
  #   text(x = as.Date(time[1]), y = changeScale(ymax), labels = paste0("  Données jusqu'au ", format(as.Date(max(time)) + dxx, "%d/%m/%Y"), 
  # "
  # 
  # Proportion p0 = C0 / (C0 + C1) parmi les tests interprétables recherchant la mutation
  # Intervalle de confiance binomial sur ce nombre de tests interprétables  
  # 
  # Attention : 
  # - Les données publiques sont données partagées déjà lissées sur 7j, ce qui atténue le signal
  # - Le nombre de résultats de criblage rendus publics est actuellement faible"), cex = 0.65, adj = c(0, 1))
  # }

  
  # Label of the horizontal axis
  #mtext("date", line = 2, side = 1)  

  xx <- base::as.Date(time)[keepPts]
  

  # Add data points (lissés)    
  points(as.Date(time), changeScale(p), 
       type = "p", col = col, pch = 16, cex = cexL)
  
  # Add confidence interval as arrows
  arrows(x0 = xx, 
         x1 = xx, 
         y0 = changeScale(pp - deltaItv), 
         y1 = changeScale(pp + deltaItv), 
         code = 0, 
         lwd = 3, 
         col = adjustcolor(col, alpha.f = 0.5), 
         lend = 1)

  
  
  # If add "delissees" data
  if(addDeliss){
    points(as.Date(timedl), changeScale(pdl), type = "p", col = coldl, pch = 16)

    xxdl <- base::as.Date(timedl)[keepPtsdl]

    # Add confidence interval as arrows
    arrows(x0 = xxdl, 
         x1 = xxdl, 
         y0 = changeScale(ppdl - deltaItvdl), 
         y1 = changeScale(ppdl + deltaItvdl), 
         code = 0, 
         lwd = 3, 
         col = adjustcolor(coldl, alpha.f = 0.5), 
         lend = 1)
  }
  

  if(addNotes){
  # Add note about data and code provenance
  mtext("Données : https://www.data.gouv.fr/fr/datasets/donnees-de-laboratoires-pour-le-depistage-indicateurs-sur-les-mutations/
Code : https://github.com/flodebarre/nouveauCriblage/blob/main/scripts/mutations.Rmd", side = 1, line = 3.5, cex = 0.5, col = gray(0.5), adj = 0, family = "mono")
    
    par(xpd = TRUE)
    if(addLegend){
      legend("topleft", col = c(col, coldl), pch = 16, legend = c("Données publiques, publiées déjà lissées", "Données délissées"), bty = "n", horiz = TRUE, cex = 0.8, pt.cex = 0.9*c(cexL, 1), inset = c(0, -0.075))
    }
    par(xpd = FALSE)
  }

  # Axes: 
  # horizontal
  xxl <- seq(as.Date(min(time)), as.Date(max(time)) + dxx, by = "day")
  axis(1, at = xxl, 
       labels = format(seq(as.Date(min(time)), as.Date(max(time)) + dxx, by = "day"), "%d/%m"), 
       las = 2, 
       cex.axis = 0.6, 
       lwd = 0)
  
  # Vertical axes
  if(scale == "linear"){
    axis(2, lwd = 0)
    axis(4, lwd = 0)
  }
  if(scale == "logit"){
    yvalues <- c(0.999, 0.99, 0.9, 0.75, 0.5, 0.25, 0.1, 0.05, 0.025, 0.01, 0.001)
    axis(2, at = changeScale(yvalues), labels = yvalues)
    axis(4, at = changeScale(yvalues), labels = yvalues)
  }
  
  if(scale == "linear"){
    mtext("Proportion criblage sans mutation L452R", side = 2, las = 0, line = 2.5)
  }
  if(scale == "logit"){
    mtext(expression(paste("p"[0], ", logit scale")), side = 2, las = 0, line = 2.5)
  }
  
  title(main = thetit)
  print(p[length(p)])
}

layout(1)
ix <- which(dat.France$dateMid >= "2021-11-01")
#plotMut0(dat.France[ix, "dateMid"], dat.France[ix, "nb_C0"], dat.France[ix, "nb_C1"], col = col452R, thetit = "Proportion des tests criblés sans la mutation L452R, France", ymin = 10^-2, ymax = 0.6)


#plotRegC0("Île-de-France", addNotes = TRUE)

layout(1)
#plotRegC0("Île-de-France", addNotes = TRUE, ymax = 0.99, addLegend = TRUE)

#plotRegC0("Île-de-France", addNotes = TRUE, ymax = 1, ymin = 0, addLegend = TRUE, scale = "linear")


```

### France 

```{r}
plotMut(dat.France$dateMid, dat.France$nb_A0, dat.France$nb_A1, col = col484K, thetit = "Proportion of cases with \nE484K, France", ymax = 0.3)
plotMut(dat.France$dateMid, dat.France$nb_B0, dat.France$nb_B1, col = col484Q, thetit = "Proportion of cases with \nE484Q, France", ymax = 0.3)
plotMut(dat.France$dateMid, dat.France$nb_C0, dat.France$nb_C1, col = col452R, thetit = "L452R, France")
```



### Regions 

```{r regionsPlot, eval = FALSE}
for(reg in unique.noNA(dat.Regions$reg_name)){
  dat <- dat.Regions[dat.Regions$reg_name == reg, ]
  plotMut(time = dat$dateMid, test0 = dat$nb_C0, test1 = dat$nb_C1, col = col452R, thetit = paste0("L452R, ", reg), ymax = 1)
}



for(reg in unique.noNA(dat.Regions$reg_name)){
  dat <- dat.Regions[which(dat.Regions$reg_name == reg & dat.Regions$date2 >= "2021-11-01"), ]
  plotMut(time = dat$date2, test0 = dat$nb_A0, test1 = dat$nb_A1, col = col484K, thetit = paste0("E484K, ", reg), ymax = 0.2)
}

```

### Specific examples

```{r}
unique(dat.Regions$nom_reg)
tmp <- dat.Regions[which(dat.Regions$nom_reg == "Provence-Alpes-Côte d'Azur" & dat.Regions$dateMid >= "2021-11-15"), ]

plotMut(time = tmp$dateMid, test0 = tmp$nb_A0, test1 = tmp$nb_A1, col = col484K, thetit = "Provence-Alpes-Côte d'Azur")

plotMut(time = tmp$dateMid, test1 = tmp$nb_C0, test0 = tmp$nb_C1, col = col452R, thetit = "Provence-Alpes-Côte d'Azur", add = TRUE)

plotMut(time = tmp$dateMid, test1 = tmp$nb_A0C0, test0 = tmp$nb_A01C01 - tmp$nb_A0C0, col = colAC, thetit = "Provence-Alpes-Côte d'Azur", add = TRUE)

legend(x = as.Date("2021-11-16"), y = 0.8, 
       col = c(col452R, colAC, col484K), 
       legend = c("Proportion non-L452R", 
                  "Proportion non-L452R and non-E484K", 
                  "Proportion E484K"), 
       pch = 16, box.lwd = 0)

```

We cannot do this anymore with the new data...

```{r, eval = FALSE}
# Source function to turn back into raw data 
source("delissage.R")
```


```{r figRegionsMapPropC0, fig.width=10, fig.height=15, eval = FALSE}

# Function to plot one region
# We set et all parameters here
plotRegC0 <- function(reg, xmin = "2021-11-01", addNotes = FALSE, ymax = 0.99, ymin = 0.5*10^-2, ...){
  dat <- dat.Regions[which(dat.Regions$reg_name == reg & dat.Regions$dateMid >= xmin), ]
  
  # Delissage
  tmp <- delissage(reg)
  tmp <- tmp[which(tmp$date2 >= xmin), ]
  
  # Export
  regNB <- unique(dat$reg)
  write.csv(tmp, file = paste0("../data/deliss_reg-", regNB, ".csv"))
  
  plotMut0(dat$dateMid, dat$nb_C0, dat$nb_C1, col = col452R, thetit = "", 
           ymin = ymin, ymax = ymax, 
           addDeliss = TRUE, 
           timedl = tmp$date2,
           test0dl = tmp$nb_C0_dl, 
           test1dl = tmp$nb_C1_dl, 
           addNotes = addNotes,...)
#ix <- which(dat.France$date2 > "2021-11-01")
#plotMut0(dat.France[ix, "date2"], dat.France[ix, "nb_C0"], dat.France[ix, "nb_C1"], col = col452R, thetit = "L452R, France", ymin = 10^-2, ymax = 0.6)
  title(main = reg)
}


#
#ix <- which(dat.France$date2 > "2021-11-01")
#plotMut0(dat.France[ix, "date2"], dat.France[ix, "nb_C0"], dat.France[ix, "nb_C1"], col = col452R, thetit = "L452R, France", ymin = 10^-2, ymax = 0.6)

layout(matrix(1:15, ncol = 3, byrow = TRUE))

# 1 Plot legend
par(mar = c(0, 0, 0, 0))
plot(0, 0, xlab = "", ylab = "", type = "n", axes = FALSE, xlim = c(-0.2, 1), ylim = c(-1, 0.5))
legend(x = -0.15, y = 0, legend = c("Données publiques, partagées déjà lissées", "Données dé-lissées"), 
          col = c(col452R, colDL), 
          pch = 16, 
          box.col = gray(0, 0), bty = "n", cex = 1)

# 2 HDF
#layout(1)
plotRegC0("Hauts-de-France")


# 3 Plot credits
par(mar = c(0, 0, 0, 0))
plot(0, 0, xlab = "", ylab = "", type = "n", axes = FALSE, xlim = c(-0.1, 1), ylim = c(-1, 1))
text(0, 0, "@flodebarre 

Data:
https://www.data.gouv.fr/fr/datasets/
donnees-de-laboratoires-pour-le-
depistage-indicateurs-sur-les-mutations/

Code: https://github.com/flodebarre/
nouveauCriblage/blob/main/scripts/mutations.Rmd
", adj = 0, cex = 0.8, family = "mono")

# 4 NOR
plotRegC0("Normandie")

# 5 IDF
# 
#layout(1)
plotRegC0("Île-de-France")

# 6 GE
plotRegC0("Grand Est")

# 7 BRE
plotRegC0("Bretagne")

# 8 CVL
plotRegC0("Centre-Val de Loire")

# 9 BFC
plotRegC0("Bourgogne-Franche-Comté")

# 10 PDL
plotRegC0("Pays de la Loire")

# 11 ARA
plotRegC0("Auvergne-Rhône-Alpes")

# 12 PACA
plotRegC0("Provence-Alpes-Côte d'Azur")

# 13 NAQ
plotRegC0("Nouvelle-Aquitaine")

# 14 OCC
plotRegC0("Occitanie")

# 15 COR
plotRegC0("Corse")
```

```{r IDF}
layout(1)
plotRegC0("Île-de-France", addNotes = TRUE, ymax = 1, ymin = 0, addLegend = TRUE, scale = "linear")
```

```{r predict}

source("projections.R")
```

#### Number tests, delisses

```{r}
colCrib <- "#91D900"
colTest <- gray(0.5)

plotCribTest <- function(regname, minDate = "2021-11-15"){
  
  # Get region number
  reg <- names(regs)[which(regs==regname)]
  
  # Load deliss data
  datreg <- read.csv(paste0("../data/deliss_reg-", reg, ".csv"))

  # Case data
  dC <- datCases[which(datCases$cl_age90 == 0 & datCases$reg == reg & datCases$jour >= min(datreg$date2)), ]
  
  datreg <- datreg[datreg$date2 >= minDate, ]
  dC <- dC[dC$jour >= minDate, ]
  
  par(mar = c(3, 3, 3, 3), xpd = TRUE, mgp = c(2.5, 0.5, 0), las = 1)
  lwdd <- 6
  plot(as.Date(dC$jour), dC$P, xlim = as.Date(c(minDate, max(dC$jour))), 
       ylim = c(0, 1.1*max(dC$P)), 
       yaxs = "i", 
       type = "h", lwd = lwdd, lend = 1, 
       col = colTest, frame.plot = FALSE, 
       xlab = "", ylab = "", axes = FALSE)
  points(as.Date(datreg$date2), datreg$nb_C0_dl + datreg$nb_C1_dl, 
         type = "h", lwd = lwdd, col = colCrib, lend = 1)
  axis(2)
  axis(4)
  xx <- seq(as.Date(minDate), as.Date(max(dC$jour)), by = "day")
  axis(1, at = xx, labels = format(xx, "%d/%m"), las = 2, cex.axis = 0.7, lwd = 0)
  
  title(regname)
}


```


```{r NbTestsCribDeliss, fig.width=10, fig.height=13}
layout(matrix(1:15, ncol = 3, byrow = TRUE))

# 1 Plot legend
par(mar = c(0, 0, 0, 0))
plot(0, 0, xlab = "", ylab = "", type = "n", axes = FALSE, xlim = c(-0.2, 1), ylim = c(-1, 0.5))
legend(x = -0.15, y = 0, legend = c("Nb de tests positifs du jour", "Nb de tests criblés et interprétables"), 
          col = c(colTest, colCrib), 
          pch = 15, 
          box.col = gray(0, 0), bty = "n", cex = 1.2)

# 2 HDF
#layout(1)
plotCribTest("Hauts-de-France")


# 3 Plot credits
par(mar = c(0, 0, 0, 0))
plot(0, 0, xlab = "", ylab = "", type = "n", axes = FALSE, xlim = c(-0.1, 1), ylim = c(-1, 1))
text(0, 0, "@flodebarre 

Data:
https://www.data.gouv.fr/fr/datasets/
donnees-de-laboratoires-pour-le-
depistage-indicateurs-sur-les-mutations/

Code: https://github.com/flodebarre/
nouveauCriblage/blob/main/scripts/mutations.Rmd
", adj = 0, cex = 0.8, family = "mono")

# 4 NOR
plotCribTest("Normandie")

# 5 IDF
# 
#layout(1)
plotCribTest("Île-de-France")

# 6 GE
plotCribTest("Grand Est")

# 7 BRE
plotCribTest("Bretagne")

# 8 CVL
plotCribTest("Centre-Val de Loire")

# 9 BFC
plotCribTest("Bourgogne-Franche-Comté")

# 10 PDL
plotCribTest("Pays de la Loire")

# 11 ARA
plotCribTest("Auvergne-Rhône-Alpes")

# 12 PACA
plotCribTest("Provence-Alpes-Côte d'Azur")

# 13 NAQ
plotCribTest("Nouvelle-Aquitaine")

# 14 OCC
plotCribTest("Occitanie")

# 15 COR
plotCribTest("Corse")
```

### Departements

```{r}
ymax <- max(1, 1.05*max(dat.Deps$nb_C1 / (dat.Deps$nb_C1 + dat.Deps$nb_C0), na.rm = TRUE))
```

```{r eval = FALSE}
for(dep in sort(unique.noNA(dat.Deps$departement))){
  dat <- dat.Deps[dat.Deps$departement == dep, ]
  plotMut(time = dat$date2, test0 = dat$nb_C0, test1 = dat$nb_C1, col = col452R, thetit = paste0("L452R, ", dep), ymax = ymax)
}
```

```{r eval = FALSE}
ymax <- max(1, 1.05*max(dat.Deps$nb_B1 / (dat.Deps$nb_B1 + dat.Deps$nb_B0), na.rm = TRUE))
for(dep in sort(unique.noNA(dat.Deps$departement))){
  dat <- dat.Deps[dat.Deps$departement == dep, ]
  plotMut(time = dat$date2, test0 = dat$nb_B0, test1 = dat$nb_B1, col = col484Q, thetit = paste0("E484Q, ", dep), ymax = ymax)
}
```

```{r}
dep <- "Val-de-Marne"
dat <- dat.Deps[which(dat.Deps$departement == dep & dat.Deps$date2 >= "2021-11-01"), ]
  plotCaseMut(time = dat$date2, test0 = dat$nb_B0, test1 = dat$nb_B1, col = col484Q, thetit = paste0("E484Q, ", dep))
  plotCaseMut(time = dat$date2, test0 = dat$nb_C0, test1 = dat$nb_C1, col = col452R, thetit = paste0("L452R, ", dep))
  plotMut(time = dat$date2, test0 = dat$nb_C0, test1 = dat$nb_C1, col = col452R, thetit = paste0("L452R, ", dep))
  plotMut0(time = dat$date2, test0 = dat$nb_C0, test1 = dat$nb_C1, col = col452R, thetit = paste0("L452R, ", dep), ymin = 0.001, ymax = 0.5)
  plotCaseMut(time = dat$date2, test0 = dat$nb_A0, test1 = dat$nb_A1, col = col484K, thetit = paste0("E484K, ", dep))
```

## Geographic
### L452R 

Source idea map: [Le Monde map](https://www.lemonde.fr/les-decodeurs/article/2020/05/05/coronavirus-age-mortalite-departements-pays-suivez-l-evolution-de-l-epidemie-en-cartes-et-graphiques_6038751_4355770.html) [| archived](https://archive.is/eJ68m)

```{r}
thrp <- 0.15
thrntot <- 30

drawRec <- function(depDat, x, y, dxy, col = col452R, thr.p = thrp, thr.n = thrntot/7, colMaj = col452R.complement){
  # depDat: dataset for this departement
  # x: x position of the bottom left corner
  # y: y position of the bottom left corner
  # dxy: rectangle size c(dx, dy)
  # col: main color
  # thr.p: threshold to plot criblage data, minimum proportion of cases
  # thr.n: threshold in terms of number of tests done
  
  relTime <- as.numeric(depDat$time)/max(as.numeric(depDat$time))
  test0 <- depDat$nb_C0
  test1 <- depDat$nb_C1
  
  denom <- 7
  n <- (test1 + test0) / denom
  p <- test1 / (test1 + test0)
  
  scale.xy <- function(z, z1, z2, zmax = 1){
    # z has to be between 0 and 1
    stopifnot(z >= 0 | z <= 1)
    z1 + (z2 - z1) * z/zmax
  }
  
  # Computation of the confidence interval
  deltaItv <- 1.96 * sqrt(p * (1-p) / n)
  keepPts <- !is.na(deltaItv) & (depDat$tx_crib/100 >= thr.p) & (n >= thr.n)
  
  if(any(keepPts)){
      # Remove points for which the itv cannot be computed
  # and point with not enough criblage
  deltaItv <- deltaItv[keepPts]
  pp <- p[keepPts]
  
  # Color depends on whether main mutation
  if(pp[length(pp)] > 0.5){
    thecol <- colMaj
  }else{
      thecol <- col
  }

  lines(scale.xy(relTime[keepPts], x, x + dxy[1]), scale.xy(pp, y, y + dxy[2]), type = "o", col = thecol, pch = 16, cex = 0.2, lwd = 0.7)
  
  xx <- relTime[keepPts]
  
  polygon(x = scale.xy(c(xx, rev(xx), xx[1]), x, x + dxy[1]), y = scale.xy(c(sapply(pp + deltaItv, min, 1), 
                                                                             sapply(rev(pp - deltaItv), max, 0), 
                                                                             sapply((pp + deltaItv)[1], min, 1)), y, y + dxy[2]), border = NA, col = adjustcolor(thecol, alpha.f = 0.3))
  }
  
}
```

```{r figMapDepL452R, fig.width = 7, fig.height = 9}
geog <- read.csv("../data/position_deps.csv", header = FALSE)
names(geog) <- c("x", "y", "dep", "shortName")
rr <- 2 # Rounding factor

d1 <- c(5.367367157581877, 1.008996513422371)
d2 <- c(6.203498009030808, 1.7266142092327605)
dd <- d2 - d1
ddr <- round(dd,rr)

par(mar = rep(0.2, 4) + c(2, 0, 2, 0))
# Initialize plot with rect positions
plot(c(round(geog$x, rr), round(geog$x, rr) + ddr[1]), c(round(geog$y, rr), round(geog$y, rr) + ddr[2]), type = "n", asp = 1, axes = FALSE, xlab = "", ylab = "")

# Add titles of the plots
text(x = round(geog$x, rr) + ddr[1]/2, y = round(geog$y, rr) + ddr[2], labels = paste0(geog$shortName, "(", geog$dep, ")"), bg = "white", adj = c(0.5, -0.4), cex = 0.45)

for(i in seq_len(nrow(geog))){
  # Draw rectangle
  rect(xleft = round(geog[i, "x"], rr), ybottom = round(geog[i, "y"], rr), xright = round(geog[i, "x"], rr) + ddr[1], ytop = round(geog[i, "y"], rr) + ddr[2], lwd = 0.5, border = gray(0.6))
  
  # Select departement data
  depDat <- dat.Deps[which(dat.Deps$dep == geog[i, "dep"]), ]
  
  # Horizontal line for 0.5
  lines(c(round(geog[i, "x"], rr), round(geog[i, "x"], rr) + ddr[1]), rep(round(geog[i, "y"], rr) + ddr[2]/2, 2), lty = 1, col = gray(0.6), lwd = 0.5)
  
  # Draw curve
  drawRec(depDat, x = round(geog[i, "x"], rr), y = round(geog[i, "y"], rr), dxy = ddr, col = col452R)

#    readline(prompt="Press [enter] to continue")

}


#drawRec(depDat, x = 5.73820184045573, y = 7.01837788404748, dxy = ddr, col = col452R)

minDay <- format(min(dat.Deps$date2), "%d %b")
maxDay <- format(max(dat.Deps$date2), "%d %b")


xP <- 1.34031283936975
yP <- 15.0106959818622
cexLeg <- 0.45
text(x = xP, y = yP, adj = c(1, 0), labels = "0% ", cex = 0.4)
text(x = xP, y = yP + ddr[2], adj = c(1, 0.5), labels = "100% ", cex = cexLeg)

text(x = c(xP, xP + ddr[1]), y = c(yP, yP), adj = c(0.5, 1.5), labels = c(minDay, maxDay), cex = cexLeg)

title("Proportion de L452R")

  mtext("  @flodebarre
  Données : https://www.data.gouv.fr/fr/datasets/donnees-de-laboratoires-pour-le-depistage-indicateurs-sur-les-mutations/
  Code : https://github.com/flodebarre/nouveauCriblage
  Idée carte : Les Decodeurs, Le Monde https://tinyurl.com/carteFRDecLM", side = 1, line = 1, cex = 0.6, col = gray(0.5), adj = 0)
  
cexLegend <- 0.6
legend("topright", legend = c("Proportion L452R, < 50% le dernier jour", "≥ 50% le dernier jour"), cex = cexLegend, bty = "n", col = c(col452R, col452R.complement), lty = 1, pch = 16)
legend("topright", legend = c("", paste0("Données tracées si au moins ", 100*thrp, "% des cas criblés
et au moins ", thrntot, " criblages sur la semaine. 
Itv confiance sur nb crib. moyen 7 derniers jours.")), cex = cexLegend, bty = "n")
```

### Absence L452R 

Source idea map: [Le Monde map](https://www.lemonde.fr/les-decodeurs/article/2020/05/05/coronavirus-age-mortalite-departements-pays-suivez-l-evolution-de-l-epidemie-en-cartes-et-graphiques_6038751_4355770.html) [| archived](https://archive.is/eJ68m)

```{r}
thrp <- 0.125
thrntot <- 30

drawRec0 <- function(depDat, x, y, dxy, col = col452R, thr.p = thrp, thr.n = thrntot/7, colMaj = col452R.complement, scale = "logit", ymin = 1*10^(-2), ymax = 1, yvals = c(0.01, 0.1, 0.5, 0.9, 0.99), ylabels = FALSE){
  # depDat: dataset for this departement
  # x: x position of the bottom left corner
  # y: y position of the bottom left corner
  # dxy: rectangle size c(dx, dy)
  # col: main color
  # thr.p: threshold to plot criblage data, minimum proportion of cases
  # thr.n: threshold in terms of number of tests done
  # scale: type of scale (logit or linear)
  # ymin: minimum y value (natural scale)
  # ymax: maximum y value (natural scale)
  # yvals: values of the horizontal lines
  # ylabels: whether to add ylines labels
  
  relTime <- (as.numeric(depDat$time) - min(as.numeric(depDat$time)))/(max(as.numeric(depDat$time)) - min(as.numeric(depDat$time)))
  test0 <- depDat$nb_C0
  test1 <- depDat$nb_C1
  
  denom <- 7
  n <- (test1 + test0) / denom
  p <- test0 / (test1 + test0)
  
  scale.xy <- function(yv, z1, z2, zmin = 0, zmax = 1){
    # Put y on the (0, 1) scale
    z <- (yv - zmin)/(zmax - zmin)
    # z is between 0 and 1 ; can go beyond with the confidence interval -> crop
    z[z < 0] <- 0
    z[z > 1] <- 1
    # Rescale z on the z1, z2 scale
    z1 + (z2 - z1) * z
  }
  
  # Compute new values on the new scale
  chgScale <- function(Z){
    out <- NA # Initialize output, have NA if scale not properly written
    if(scale == "logit"){
      # Crop values, can be outside of (0, 1) when confidence interval
      pf <- Z
      pf[pf < ymin] <- ymin
      pf[pf > ymax] <- ymax
      # Compute logit
      out <- log(pf /(1-pf)) # Logit scale
#      print("coucou1")
    }
    if(scale == "linear"){
      out <- p # Linear scale, no change
    }
    out
  }

  
  # Computation of the confidence interval
  deltaItv <- 1.96 * sqrt(p * (1-p) / n)
  keepPts <- !is.na(deltaItv) & (depDat$tx_crib/100 >= thr.p) & (n >= thr.n)
  
  if(any(keepPts)){
  #  print("coucou")
      
  # Remove points for which the itv cannot be computed
  # and point with not enough criblage
  deltaItv <- deltaItv[keepPts]
  pp <- p[keepPts]
  rT <- relTime[keepPts]
  
  # Get confidence interval values
  itvm <- pp - deltaItv
  itvM <- pp + deltaItv
  
  # Crop confidence interval values to the plot range
  
  # Color depends on whether main mutation
  if(pp[length(pp)] > 0.5){
    thecol <- colMaj
  }else{
    thecol <- col
  }

#print(scale.xy(rT, x, x + dxy[1]))
#print(pp)
#print(pp - deltaItv)
#print(chgScale(pp - deltaItv))
#print(chgScale)
#print(scale.xy(chgScale(pp - deltaItv), y, y + dxy[2], zmin = chgScale(ymin), zmax = chgScale(ymax)))

  arrows(x0 = scale.xy(rT, x, x + dxy[1]), 
         x1 = scale.xy(rT, x, x + dxy[1]), 
         y0 = scale.xy(chgScale(pp - deltaItv), y, y + dxy[2], zmin = chgScale(ymin), zmax = chgScale(ymax)), 
         y1 = scale.xy(chgScale(pp + deltaItv), y, y + dxy[2], zmin = chgScale(ymin), zmax = chgScale(ymax)), 
         code = 0, 
         lwd = 1, 
         col = adjustcolor(thecol, alpha.f = 0.5), 
         lend = 1)
  
  # Horizontal lines at specific values
  nh <- length(yvals)
  arrows(x0 = scale.xy(rep(0, nh), x, x + dxy[1]), 
         x1 = scale.xy(rep(1, nh), x, x + dxy[1]), 
         y0 = scale.xy(chgScale(yvals), y, y + dxy[2], zmin = chgScale(ymin), zmax = chgScale(ymax)), 
         y1 = scale.xy(chgScale(yvals), y, y + dxy[2], zmin = chgScale(ymin), zmax = chgScale(ymax)), 
         col = gray(0.8), 
         lend = 1, 
         code = 0, 
         lwd= 0.8
         )
  
  # 0.5 more visually striking
  if(is.element(0.5, yvals)){
    arrows(x0 = scale.xy(0, x, x + dxy[1]), 
         x1 = scale.xy(1, x, x + dxy[1]), 
         y0 = scale.xy(chgScale(0.5), y, y + dxy[2], zmin = chgScale(ymin), zmax = chgScale(ymax)), 
         y1 = scale.xy(chgScale(0.5), y, y + dxy[2], zmin = chgScale(ymin), zmax = chgScale(ymax)), 
         col = gray(0.8), 
         lend = 1, 
         code = 0, 
         lwd= 2
         )
  }
  
  # Add labels
  if(ylabels){
    dxx <- 0.1
    text(x = scale.xy(rep(max(rT), nh), x + dxx, x + dxy[1] + dxx), 
         y = scale.xy(chgScale(yvals), y, y + dxy[2], zmin = chgScale(ymin), zmax = chgScale(ymax)), 
         labels = yvals, 
         adj = c(0, 0.5), 
         cex = 0.45)
  }
  
  
#  print(pp)
#  print(chgScale(pp))
#  print(chgScale(ymin))
#  print(chgScale(ymax))

    points(scale.xy(rT, x, x + dxy[1]), 
         scale.xy(yv = chgScale(pp), y, y + dxy[2], zmin = chgScale(ymin), zmax = chgScale(ymax)), 
         type = "p", col = thecol, pch = 16, cex = 0.2, lwd = 0.7)
  
  }
}

# This is only here for testing new stuff quickly
#drawRec0(depDat, x = round(geog[i, "x"], rr), y = round(geog[i, "y"], rr), dxy = ddr, col = col452R)

```

```{r figMapDepAbsL452R, fig.width = 7, fig.height = 9}
geog <- read.csv("../data/position_deps.csv", header = FALSE)
names(geog) <- c("x", "y", "dep", "shortName")
rr <- 2 # Rounding factor

d1 <- c(5.367367157581877, 1.008996513422371)
d2 <- c(6.203498009030808, 1.7266142092327605)
dd <- d2 - d1
ddr <- round(dd,rr)

initDate <- "2021-12-01"
ymin <- 1*10^(-2)
ymax <- 0.9
yvals <- c(0.01, 0.1, 0.5, 0.9)

par(mar = rep(0.2, 4) + c(2, 0, 2, 0))
# Initialize plot with rect positions
plot(c(round(geog$x, rr), round(geog$x, rr) + ddr[1]), c(round(geog$y, rr), round(geog$y, rr) + ddr[2]), type = "n", asp = 1, axes = FALSE, xlab = "", ylab = "")

# Add titles of the plots
text(x = round(geog$x, rr) + ddr[1]/2, y = round(geog$y, rr) + ddr[2], labels = paste0(geog$shortName, "(", geog$dep, ")"), bg = "white", adj = c(0.5, -0.4), cex = 0.45)

for(i in seq_len(nrow(geog))){
  # Draw rectangle
  rect(xleft = round(geog[i, "x"], rr), ybottom = round(geog[i, "y"], rr), xright = round(geog[i, "x"], rr) + ddr[1], ytop = round(geog[i, "y"], rr) + ddr[2], lwd = 0.5, border = gray(0.6))
  
  # Select departement data
  depDat <- dat.Deps[which(dat.Deps$dep == geog[i, "dep"] & dat.Deps$date2 >= initDate), ]
  
  # Horizontal line for 0.5
 #  lines(c(round(geog[i, "x"], rr), round(geog[i, "x"], rr) + ddr[1]), rep(round(geog[i, "y"], rr) + ddr[2]/2, 2), lty = 1, col = gray(0.6), lwd = 0.5)
  
  # Draw curve
  if(geog[i, "dep"] == "75"){
    ylb <- TRUE
  }else{
    ylb <- FALSE
  }
  drawRec0(depDat, x = round(geog[i, "x"], rr), y = round(geog[i, "y"], rr), dxy = ddr, col = col452R, 
           ymin = ymin, ymax = ymax, 
           ylabels = ylb, 
           yvals = yvals)

#    readline(prompt="Press [enter] to continue")

}


#drawRec(depDat, x = 5.73820184045573, y = 7.01837788404748, dxy = ddr, col = col452R)

minDay <- format(as.Date(initDate), "%d %b")
maxDay <- format(max(dat.Deps$dateMid), "%d %b")


# xP <- 1.34031283936975
# yP <- 15.0106959818622
# cexLeg <- 0.45
# text(x = xP, y = yP, adj = c(1, 0), labels = ymin, cex = 0.4)
# text(x = xP, y = yP + ddr[2], adj = c(1, 0.5), labels = ymax, cex = cexLeg)

text(x = c(xP, xP + ddr[1]), y = c(yP, yP), adj = c(0.5, 1.5), labels = c(minDay, maxDay), cex = cexLeg)

title("Absence de L452R, échelle logit")

  mtext(paste0("  @flodebarre, mise à jour ", Sys.Date(), "
  Données : https://www.data.gouv.fr/fr/datasets/donnees-de-laboratoires-pour-le-depistage-indicateurs-sur-les-mutations/
  Code : https://github.com/flodebarre/nouveauCriblage
  Idée carte : Les Decodeurs, Le Monde https://tinyurl.com/carteFRDecLM"), side = 1, line = 1, cex = 0.525, col = gray(0.5), adj = 0, family = "mono")
  
cexLegend <- 0.55
#legend("topright", legend = c("Proportion L452R, < 50% le dernier jour", "≥ 50% le dernier jour"), cex = cexLegend, bty = "n", col = c(col452R, col452R.complement), lty = 1, pch = 16)
legend("topright", legend = c(paste0("Données tracées si au moins ", 100*thrp, "% des cas criblés
et au moins ", thrntot, " criblages sur la semaine. 
Itv confiance sur nb crib. moyen 7 derniers jours.

Attention : 
- les données publiques sont lissées, ce qui atténue le signal
- il y a de moins en moins de criblage dans les données publiques")), cex = cexLegend, bty = "n", adj = c(0, 0))
```

### E484K/Q

```{r}

thrp <- 0.1
thrntot <- 30

drawRec2 <- function(depDat, x, y, dxy, col = col484K, thr.p = thrp, thr.n = thrntot/7, colMaj = col452R.complement){
  # depDat: dataset for this departement
  # x: x position of the bottom left corner
  # y: y position of the bottom left corner
  # dxy: rectangle size c(dx, dy)
  # col: main color
  # thr.p: threshold to plot criblage data, minimum proportion of cases
  # thr.n: threshold in terms of number of tests done
  
  relTime <- as.numeric(depDat$time)/max(as.numeric(depDat$time))
  test0 <- depDat$nb_A0 + depDat$nb_B0
  test1 <- depDat$nb_A1 + depDat$nb_B1
  
  denom <- 7
  n <- (test1 + test0) / denom
  p <- test1 / (test1 + test0)
  
  scale.xy <- function(z, z1, z2){
    # z has to be between 0 and 1
    stopifnot(z >= 0 | z <= 1)
    z1 + (z2 - z1) * z
  }
  
  # Computation of the confidence interval
  deltaItv <- 1.96 * sqrt(p * (1-p) / n)
  keepPts <- !is.na(deltaItv) & (n/(depDat$nb_pos/denom) >= thr.p) & (n >= thr.n)
  
  if(any(keepPts)){
      # Remove points for which the itv cannot be computed
  # and point with not enough criblage
  deltaItv <- deltaItv[keepPts]
  pp <- p[keepPts]
  
  # Color depends on whether main mutation
  if(pp[length(pp)] > 0.5){
    thecol <- colMaj
  }else{
      thecol <- col
  }

  lines(scale.xy(relTime[keepPts], x, x + dxy[1]), scale.xy(pp, y, y + dxy[2]), type = "o", col = thecol, pch = 16, cex = 0.2, lwd = 0.7)
  
  xx <- relTime[keepPts]
  
  polygon(x = scale.xy(c(xx, rev(xx), xx[1]), x, x + dxy[1]), y = scale.xy(c(sapply(pp + deltaItv, min, 1), 
                                                                             sapply(rev(pp - deltaItv), max, 0), 
                                                                             sapply((pp + deltaItv)[1], min, 1)), y, y + dxy[2]), border = NA, col = adjustcolor(thecol, alpha.f = 0.3))
  }
  
}
```

```{r figMapDepE484, fig.width = 7, fig.height = 9}

par(mar = rep(0.2, 4) + c(2, 0, 2, 0))
# Initialize plot with rect positions
plot(c(round(geog$x, rr), round(geog$x, rr) + ddr[1]), c(round(geog$y, rr), round(geog$y, rr) + ddr[2]), type = "n", asp = 1, axes = FALSE, xlab = "", ylab = "")

# Add titles of the plots
text(x = round(geog$x, rr) + ddr[1]/2, y = round(geog$y, rr) + ddr[2], labels = paste0(geog$shortName, "(", geog$dep, ")"), bg = "white", adj = c(0.5, -0.4), cex = 0.45)

for(i in seq_len(nrow(geog))){
  # Draw rectangle
  rect(xleft = round(geog[i, "x"], rr), ybottom = round(geog[i, "y"], rr), xright = round(geog[i, "x"], rr) + ddr[1], ytop = round(geog[i, "y"], rr) + ddr[2], lwd = 0.5, border = gray(0.6))
  
  # Select departement data
  depDat <- dat.Deps[which(dat.Deps$dep == geog[i, "dep"]), ]
  
  # Horizontal line for 0.5
  lines(c(round(geog[i, "x"], rr), round(geog[i, "x"], rr) + ddr[1]), rep(round(geog[i, "y"], rr) + ddr[2]/2, 2), lty = 1, col = gray(0.6), lwd = 0.5)
  
  # Draw curve
  drawRec2(depDat, x = round(geog[i, "x"], rr), y = round(geog[i, "y"], rr), dxy = ddr, col = col484K)

#    readline(prompt="Press [enter] to continue")

}


#drawRec(depDat, x = 5.73820184045573, y = 7.01837788404748, dxy = ddr, col = col452R)

minDay <- format(min(dat.Deps$date2), "%d %b")
maxDay <- format(max(dat.Deps$date2), "%d %b")


xP <- 1.34031283936975
yP <- 15.0106959818622
cexLeg <- 0.45
text(x = xP, y = yP, adj = c(1, 0), labels = "0% ", cex = 0.4)
text(x = xP, y = yP + ddr[2], adj = c(1, 0.5), labels = "100% ", cex = cexLeg)

text(x = c(xP, xP + ddr[1]), y = c(yP, yP), adj = c(0.5, 1.5), labels = c(minDay, maxDay), cex = cexLeg)

title("Proportion de E484K/Q")

  mtext("  @flodebarre
  Données : https://www.data.gouv.fr/fr/datasets/donnees-de-laboratoires-pour-le-depistage-indicateurs-sur-les-mutations/
  Code : https://github.com/flodebarre/nouveauCriblage
  Idée carte : Les Decodeurs, Le Monde https://tinyurl.com/carteFRDecLM", side = 1, line = 1, cex = 0.6, col = gray(0.5), adj = 0)
  
cexLegend <- 0.6
legend("topright", legend = c("Proportion E484K/Q, < 50% le dernier jour", "≥ 50% le dernier jour"), cex = cexLegend, bty = "n", col = c(col484K, col452R.complement), lty = 1, pch = 16)
legend("topright", legend = c("", paste0("Données tracées si au moins ", 100*thrp, "% des cas criblés
et au moins ", thrntot, " criblages sur la semaine. 
Itv confiance sur nb crib. moyen 7 derniers jours.")), cex = cexLegend, bty = "n")
```


# Other

```{r}
dat <- dat.Deps[dat.Deps$departement == "Somme", ]
  plotNbCrib(dat)
  title("Somme")
  
    plotMut(time = dat$date2, test0 = dat$nb_C0, test1 = dat$nb_C1, col = col452R, thetit = paste0("L452R, ", "Somme"), ymax = ymax)

```
